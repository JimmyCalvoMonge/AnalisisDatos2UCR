{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd33b75b-24f2-427d-a7b2-66f4201e70c4",
   "metadata": {},
   "source": [
    "<style>\n",
    "    .title_container {\n",
    "        margin: auto;\n",
    "        background: rgb(81,92,103);\n",
    "        background: linear-gradient(90deg, rgba(81,92,103,1) 36%, rgba(12,35,66,1) 62%);\n",
    "        border-radius: 7px;\n",
    "        color: white;\n",
    "        text-align:center;\n",
    "        width:75%;\n",
    "        padding-top:2%;\n",
    "        padding-bottom:2%;\n",
    "    }\n",
    "    \n",
    "    .question_container {\n",
    "        margin: auto;\n",
    "        background: rgb(84,138,142);\n",
    "        background: linear-gradient(90deg, rgba(84,138,142,1) 41%, rgba(145,201,73,1) 81%);\n",
    "        border-radius: 7px;\n",
    "        color: white;\n",
    "        text-align:left;\n",
    "        width:75%;\n",
    "        padding-top:1%;\n",
    "        padding-bottom:1%;\n",
    "        padding-left: 2%;\n",
    "        margin-top:2%;\n",
    "    }\n",
    "    \n",
    "    .question_container p {\n",
    "        font-size: 16px;\n",
    "    }\n",
    "    \n",
    "    .alert_container {\n",
    "        margin: auto;\n",
    "        background: rgb(142,94,84);\n",
    "        background: linear-gradient(128deg, rgba(142,94,84,1) 13%, rgba(201,103,73,1) 69%);\n",
    "        border-radius: 7px;\n",
    "        color: white;\n",
    "        text-align:left;\n",
    "        width:75%;\n",
    "        padding-top:1%;\n",
    "        padding-bottom:1%;\n",
    "        padding-left: 2%;\n",
    "        margin-top:2%;\n",
    "    }\n",
    "    \n",
    "    .alert_container p {\n",
    "        font-size: 16px;\n",
    "    }\n",
    "    \n",
    "    .code_span {\n",
    "        background-color: #E2E7EC;\n",
    "        padding:2px;\n",
    "        border-radius:1px;\n",
    "        font-family: Consolas,monaco,monospace;\n",
    "        color:black;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d925c-87b8-4e8f-86fd-db008e3e1e5d",
   "metadata": {},
   "source": [
    "<div class ='title_container'>\n",
    "    <h1> Análisis de Datos II </h1>\n",
    "    <h2> Profesor: Oldemar Rodríguez </h2>\n",
    "    <h3> Estudiante: Jimmy Calvo Monge </h3>\n",
    "    <h3> Carné: B31281 </h3>\n",
    "    <hr style='color:white; width:80%;'>\n",
    "    <h4> TAREA 12 </h4>\n",
    "    <h4> Fecha de entrega: 20 de Noviembre de 2022 </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d287e6a4-124c-4cbb-80ac-c5861e4f03e2",
   "metadata": {},
   "source": [
    "Importamos los módulos necesarios para resolver esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816bdbad-6a42-42c8-9c87-e1b0e82a884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Basicos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "\n",
    "### Utilidades/Varios\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "from matplotlib.patches import Circle\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "import seaborn as sns\n",
    "import time\n",
    "import graphviz\n",
    "import os\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "### Training/Testing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "### predictPy\n",
    "from predictPy import Analisis_Predictivo\n",
    "\n",
    "### Validacion Cruzada\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "### Modelos:\n",
    "# MLPClassifier:\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "### Clase MatConf de la Tarea 2\n",
    "class MatConf:\n",
    "    \n",
    "    def __init__(self,matriz):\n",
    "        \n",
    "        self.mat_conf = matriz\n",
    "        \n",
    "        VN = self.mat_conf[0,0]\n",
    "        VP = self.mat_conf[1,1]\n",
    "        FP = self.mat_conf[0,1]\n",
    "        FN = self.mat_conf[1,0]\n",
    "        \n",
    "        dict_medidas = {\n",
    "            'Precisión Global' : (VN+VP)/(VN+FP+FN+VP),\n",
    "            'Error Global' : (FN+FP)/(VN+FP+FN+VP),\n",
    "            'Precisión Positiva (PP)' : VP/(FN+VP),\n",
    "            'Precisión Negativa (PN)' : VN/(VN+FP),\n",
    "            'Proporción de Falsos Positivos (PFP)' : FP/(VN+FP),\n",
    "            'Proporción de Falsos Negativos (PFN)' : FN/(FN+VP),\n",
    "            'Asertividad Positiva (AP)' : VP/(FP+VP),\n",
    "            'Asertividad Negativa (AN)' : VN/(VN+FN)\n",
    "        }\n",
    "        self.dict_medidas = dict_medidas\n",
    "        \n",
    "    def __str__(self):\n",
    "        mensaje=\"Estos son los resultados para esta matriz de confusion:\"\n",
    "        for key in list(self.dict_medidas.keys()):\n",
    "            mensaje = mensaje + f\"\\n - {key}: {self.dict_medidas[key]}\"\n",
    "        return mensaje\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3565f9-2f66-4a1f-b44d-61d4de122857",
   "metadata": {},
   "source": [
    "<div class='question_container'>\n",
    "    <h2> Pregunta 1 </h2>\n",
    "    <p> La tabla de datos <code>novatosNBA.csv</code> contiene diferentes métricas de desempeño de novatos de la NBA en su primera temporada. Para esta tabla, las 21 primeras columnas corresponden a las variables predictoras y la variable <code>Permanencia</code> es la variable a predecir, la cual indica si el jugador permanece en la NBA luego de 5 años. La tabla contiene 1340 filas (individuos) y 21 columnas (variables), con la tabla realice lo siguiente: </p>\n",
    "    <ul>\n",
    "    <li> Usando el paquete <code>MLPClassifier</code> en <code>Python</code> genere modelos predictivos usando un 75% de los datos para tabla aprendizaje y un 25% para la tabla testing. Genere al menos 2 modelos con configuraciones diferentes en los parámetros vistos en clase (<code>hidden_layer_sizes</code>, <code>activation</code>, <code>solver</code>). Realice lo anterior sin estandarizar los datos y luego con los datos estandarizados, es decir, al menos 4 modelos. Para estandarizar los datos utilice la clase <code>StandardScaler</code> de <code>sklearn.preprocessing</code> </li>\n",
    "    <li> Para cada modelo obtenga los índices de precisión, compare e interprete los resultados y\n",
    "las diferencias entre los modelos con datos estandarizados y los que no. </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195a310e-367f-45ae-92d6-4ccb26f72607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PartidosJugados</th>\n",
       "      <th>MinutosJugados</th>\n",
       "      <th>PuntosPorJuego</th>\n",
       "      <th>PuntosCampoAnotados</th>\n",
       "      <th>PuntosCampoIntentados</th>\n",
       "      <th>PuntosCampoPorcentaje</th>\n",
       "      <th>Puntos3Anotados</th>\n",
       "      <th>Puntos3Intentados</th>\n",
       "      <th>Puntos3Porcentaje</th>\n",
       "      <th>TirosLibresRealizados</th>\n",
       "      <th>TirosLibresIntentados</th>\n",
       "      <th>TirosLibresPorcentaje</th>\n",
       "      <th>RebotesOfensivos</th>\n",
       "      <th>RebotesDefensivos</th>\n",
       "      <th>Rebotes</th>\n",
       "      <th>Asistencias</th>\n",
       "      <th>Robos</th>\n",
       "      <th>Bloqueos</th>\n",
       "      <th>PerdidaBalon</th>\n",
       "      <th>Permanencia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nombre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Brandon Ingram</th>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrew Harrison</th>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JaKarr Sampson</th>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malik Sealy</th>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matt Geiger</th>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PartidosJugados  MinutosJugados  PuntosPorJuego  \\\n",
       "Nombre                                                             \n",
       "Brandon Ingram                36            27.4             7.4   \n",
       "Andrew Harrison               35            26.9             7.2   \n",
       "JaKarr Sampson                74            15.3             5.2   \n",
       "Malik Sealy                   58            11.6             5.7   \n",
       "Matt Geiger                   48            11.5             4.5   \n",
       "\n",
       "                 PuntosCampoAnotados  PuntosCampoIntentados  \\\n",
       "Nombre                                                        \n",
       "Brandon Ingram                   2.6                    7.6   \n",
       "Andrew Harrison                  2.0                    6.7   \n",
       "JaKarr Sampson                   2.0                    4.7   \n",
       "Malik Sealy                      2.3                    5.5   \n",
       "Matt Geiger                      1.6                    3.0   \n",
       "\n",
       "                 PuntosCampoPorcentaje  Puntos3Anotados  Puntos3Intentados  \\\n",
       "Nombre                                                                       \n",
       "Brandon Ingram                    34.7              0.5                2.1   \n",
       "Andrew Harrison                   29.6              0.7                2.8   \n",
       "JaKarr Sampson                    42.2              0.4                1.7   \n",
       "Malik Sealy                       42.6              0.1                0.5   \n",
       "Matt Geiger                       52.4              0.0                0.1   \n",
       "\n",
       "                 Puntos3Porcentaje  TirosLibresRealizados  \\\n",
       "Nombre                                                      \n",
       "Brandon Ingram                25.0                    1.6   \n",
       "Andrew Harrison               23.5                    2.6   \n",
       "JaKarr Sampson                24.4                    0.9   \n",
       "Malik Sealy                   22.6                    0.9   \n",
       "Matt Geiger                    0.0                    1.3   \n",
       "\n",
       "                 TirosLibresIntentados  TirosLibresPorcentaje  \\\n",
       "Nombre                                                          \n",
       "Brandon Ingram                     2.3                   69.9   \n",
       "Andrew Harrison                    3.4                   76.5   \n",
       "JaKarr Sampson                     1.3                   67.0   \n",
       "Malik Sealy                        1.3                   68.9   \n",
       "Matt Geiger                        1.9                   67.4   \n",
       "\n",
       "                 RebotesOfensivos  RebotesDefensivos  Rebotes  Asistencias  \\\n",
       "Nombre                                                                       \n",
       "Brandon Ingram                0.7                3.4      4.1          1.9   \n",
       "Andrew Harrison               0.5                2.0      2.4          3.7   \n",
       "JaKarr Sampson                0.5                1.7      2.2          1.0   \n",
       "Malik Sealy                   1.0                0.9      1.9          0.8   \n",
       "Matt Geiger                   1.0                1.5      2.5          0.3   \n",
       "\n",
       "                 Robos  Bloqueos  PerdidaBalon  Permanencia  \n",
       "Nombre                                                       \n",
       "Brandon Ingram     0.4       0.4           1.3            0  \n",
       "Andrew Harrison    1.1       0.5           1.6            0  \n",
       "JaKarr Sampson     0.5       0.3           1.0            0  \n",
       "Malik Sealy        0.6       0.1           1.0            1  \n",
       "Matt Geiger        0.3       0.4           0.8            1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_novatos = pd.read_csv(\"novatosNBA.csv\",sep=\";\",index_col=0)\n",
    "datos_novatos.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b5744ef-1cae-4ff4-a97c-403675924ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PartidosJugados': 0,\n",
       " 'MinutosJugados': 0,\n",
       " 'PuntosPorJuego': 0,\n",
       " 'PuntosCampoAnotados': 0,\n",
       " 'PuntosCampoIntentados': 0,\n",
       " 'PuntosCampoPorcentaje': 0,\n",
       " 'Puntos3Anotados': 0,\n",
       " 'Puntos3Intentados': 0,\n",
       " 'Puntos3Porcentaje': 11,\n",
       " 'TirosLibresRealizados': 0,\n",
       " 'TirosLibresIntentados': 0,\n",
       " 'TirosLibresPorcentaje': 0,\n",
       " 'RebotesOfensivos': 0,\n",
       " 'RebotesDefensivos': 0,\n",
       " 'Rebotes': 0,\n",
       " 'Asistencias': 0,\n",
       " 'Robos': 0,\n",
       " 'Bloqueos': 0,\n",
       " 'PerdidaBalon': 0,\n",
       " 'Permanencia': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hay datos faltantes:\n",
    "nas_dict={}\n",
    "for col in datos_novatos.columns:\n",
    "    nas_dict[col]=datos_novatos[col].isna().sum()\n",
    "nas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a374d07c-c9c4-48bb-b0a6-2631292b1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_novatos = datos_novatos.dropna() ### Eliminamos los fatos faltantes por ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18bdff99-dcc9-49c4-9dd8-242343c3e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datos_novatos.drop(['Permanencia'],axis=1)\n",
    "y = datos_novatos['Permanencia']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172b8ec7-13f7-4019-9830-191a1e876409",
   "metadata": {},
   "source": [
    "Estandarizamos los datos para estos dos primeros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e17019-9354-4642-acaa-da25a286b003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PartidosJugados</th>\n",
       "      <th>MinutosJugados</th>\n",
       "      <th>PuntosPorJuego</th>\n",
       "      <th>PuntosCampoAnotados</th>\n",
       "      <th>PuntosCampoIntentados</th>\n",
       "      <th>PuntosCampoPorcentaje</th>\n",
       "      <th>Puntos3Anotados</th>\n",
       "      <th>Puntos3Intentados</th>\n",
       "      <th>Puntos3Porcentaje</th>\n",
       "      <th>TirosLibresRealizados</th>\n",
       "      <th>TirosLibresIntentados</th>\n",
       "      <th>TirosLibresPorcentaje</th>\n",
       "      <th>RebotesOfensivos</th>\n",
       "      <th>RebotesDefensivos</th>\n",
       "      <th>Rebotes</th>\n",
       "      <th>Asistencias</th>\n",
       "      <th>Robos</th>\n",
       "      <th>Bloqueos</th>\n",
       "      <th>PerdidaBalon</th>\n",
       "      <th>Permanencia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nombre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Brandon Ingram</th>\n",
       "      <td>-1.396466</td>\n",
       "      <td>1.171517</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>-0.020616</td>\n",
       "      <td>0.471865</td>\n",
       "      <td>-1.539520</td>\n",
       "      <td>0.651138</td>\n",
       "      <td>1.235944</td>\n",
       "      <td>0.355367</td>\n",
       "      <td>0.300531</td>\n",
       "      <td>0.356433</td>\n",
       "      <td>-0.048365</td>\n",
       "      <td>-0.394923</td>\n",
       "      <td>1.012191</td>\n",
       "      <td>0.519775</td>\n",
       "      <td>0.231411</td>\n",
       "      <td>-0.537044</td>\n",
       "      <td>0.079043</td>\n",
       "      <td>0.143591</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrew Harrison</th>\n",
       "      <td>-1.453692</td>\n",
       "      <td>1.111452</td>\n",
       "      <td>0.087038</td>\n",
       "      <td>-0.376442</td>\n",
       "      <td>0.221689</td>\n",
       "      <td>-2.373236</td>\n",
       "      <td>1.171343</td>\n",
       "      <td>1.894176</td>\n",
       "      <td>0.261716</td>\n",
       "      <td>1.311686</td>\n",
       "      <td>1.185898</td>\n",
       "      <td>0.581052</td>\n",
       "      <td>-0.651701</td>\n",
       "      <td>-0.015746</td>\n",
       "      <td>-0.304835</td>\n",
       "      <td>1.452906</td>\n",
       "      <td>1.168699</td>\n",
       "      <td>0.312485</td>\n",
       "      <td>0.557843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JaKarr Sampson</th>\n",
       "      <td>0.778130</td>\n",
       "      <td>-0.282057</td>\n",
       "      <td>-0.371255</td>\n",
       "      <td>-0.376442</td>\n",
       "      <td>-0.334258</td>\n",
       "      <td>-0.313466</td>\n",
       "      <td>0.391035</td>\n",
       "      <td>0.859812</td>\n",
       "      <td>0.317907</td>\n",
       "      <td>-0.407277</td>\n",
       "      <td>-0.397626</td>\n",
       "      <td>-0.324927</td>\n",
       "      <td>-0.651701</td>\n",
       "      <td>-0.236018</td>\n",
       "      <td>-0.401848</td>\n",
       "      <td>-0.379336</td>\n",
       "      <td>-0.293367</td>\n",
       "      <td>-0.154398</td>\n",
       "      <td>-0.270661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malik Sealy</th>\n",
       "      <td>-0.137489</td>\n",
       "      <td>-0.726539</td>\n",
       "      <td>-0.256682</td>\n",
       "      <td>-0.198529</td>\n",
       "      <td>-0.111880</td>\n",
       "      <td>-0.248077</td>\n",
       "      <td>-0.389273</td>\n",
       "      <td>-0.268585</td>\n",
       "      <td>0.205525</td>\n",
       "      <td>-0.407277</td>\n",
       "      <td>-0.397626</td>\n",
       "      <td>-0.143731</td>\n",
       "      <td>-0.009757</td>\n",
       "      <td>-0.823410</td>\n",
       "      <td>-0.547367</td>\n",
       "      <td>-0.515058</td>\n",
       "      <td>-0.049689</td>\n",
       "      <td>-0.621281</td>\n",
       "      <td>-0.270661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matt Geiger</th>\n",
       "      <td>-0.709751</td>\n",
       "      <td>-0.738552</td>\n",
       "      <td>-0.531657</td>\n",
       "      <td>-0.613660</td>\n",
       "      <td>-0.806813</td>\n",
       "      <td>1.353966</td>\n",
       "      <td>-0.649376</td>\n",
       "      <td>-0.644718</td>\n",
       "      <td>-1.205486</td>\n",
       "      <td>-0.002815</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>-0.286780</td>\n",
       "      <td>-0.009757</td>\n",
       "      <td>-0.382866</td>\n",
       "      <td>-0.256329</td>\n",
       "      <td>-0.854362</td>\n",
       "      <td>-0.780722</td>\n",
       "      <td>0.079043</td>\n",
       "      <td>-0.546829</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PartidosJugados  MinutosJugados  PuntosPorJuego  \\\n",
       "Nombre                                                             \n",
       "Brandon Ingram         -1.396466        1.171517        0.132867   \n",
       "Andrew Harrison        -1.453692        1.111452        0.087038   \n",
       "JaKarr Sampson          0.778130       -0.282057       -0.371255   \n",
       "Malik Sealy            -0.137489       -0.726539       -0.256682   \n",
       "Matt Geiger            -0.709751       -0.738552       -0.531657   \n",
       "\n",
       "                 PuntosCampoAnotados  PuntosCampoIntentados  \\\n",
       "Nombre                                                        \n",
       "Brandon Ingram             -0.020616               0.471865   \n",
       "Andrew Harrison            -0.376442               0.221689   \n",
       "JaKarr Sampson             -0.376442              -0.334258   \n",
       "Malik Sealy                -0.198529              -0.111880   \n",
       "Matt Geiger                -0.613660              -0.806813   \n",
       "\n",
       "                 PuntosCampoPorcentaje  Puntos3Anotados  Puntos3Intentados  \\\n",
       "Nombre                                                                       \n",
       "Brandon Ingram               -1.539520         0.651138           1.235944   \n",
       "Andrew Harrison              -2.373236         1.171343           1.894176   \n",
       "JaKarr Sampson               -0.313466         0.391035           0.859812   \n",
       "Malik Sealy                  -0.248077        -0.389273          -0.268585   \n",
       "Matt Geiger                   1.353966        -0.649376          -0.644718   \n",
       "\n",
       "                 Puntos3Porcentaje  TirosLibresRealizados  \\\n",
       "Nombre                                                      \n",
       "Brandon Ingram            0.355367               0.300531   \n",
       "Andrew Harrison           0.261716               1.311686   \n",
       "JaKarr Sampson            0.317907              -0.407277   \n",
       "Malik Sealy               0.205525              -0.407277   \n",
       "Matt Geiger              -1.205486              -0.002815   \n",
       "\n",
       "                 TirosLibresIntentados  TirosLibresPorcentaje  \\\n",
       "Nombre                                                          \n",
       "Brandon Ingram                0.356433              -0.048365   \n",
       "Andrew Harrison               1.185898               0.581052   \n",
       "JaKarr Sampson               -0.397626              -0.324927   \n",
       "Malik Sealy                  -0.397626              -0.143731   \n",
       "Matt Geiger                   0.054810              -0.286780   \n",
       "\n",
       "                 RebotesOfensivos  RebotesDefensivos   Rebotes  Asistencias  \\\n",
       "Nombre                                                                        \n",
       "Brandon Ingram          -0.394923           1.012191  0.519775     0.231411   \n",
       "Andrew Harrison         -0.651701          -0.015746 -0.304835     1.452906   \n",
       "JaKarr Sampson          -0.651701          -0.236018 -0.401848    -0.379336   \n",
       "Malik Sealy             -0.009757          -0.823410 -0.547367    -0.515058   \n",
       "Matt Geiger             -0.009757          -0.382866 -0.256329    -0.854362   \n",
       "\n",
       "                    Robos  Bloqueos  PerdidaBalon  Permanencia  \n",
       "Nombre                                                          \n",
       "Brandon Ingram  -0.537044  0.079043      0.143591            0  \n",
       "Andrew Harrison  1.168699  0.312485      0.557843            0  \n",
       "JaKarr Sampson  -0.293367 -0.154398     -0.270661            0  \n",
       "Malik Sealy     -0.049689 -0.621281     -0.270661            1  \n",
       "Matt Geiger     -0.780722  0.079043     -0.546829            1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_novatos_std = datos_novatos.copy()\n",
    "datos_novatos_std.iloc[:,0:19] = StandardScaler().fit_transform(datos_novatos_std.iloc[:,0:19])\n",
    "datos_novatos_std.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1c558a7-f4a8-4378-903c-8b5497290fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PartidosJugados</th>\n",
       "      <th>MinutosJugados</th>\n",
       "      <th>PuntosPorJuego</th>\n",
       "      <th>PuntosCampoAnotados</th>\n",
       "      <th>PuntosCampoIntentados</th>\n",
       "      <th>PuntosCampoPorcentaje</th>\n",
       "      <th>Puntos3Anotados</th>\n",
       "      <th>Puntos3Intentados</th>\n",
       "      <th>Puntos3Porcentaje</th>\n",
       "      <th>TirosLibresRealizados</th>\n",
       "      <th>TirosLibresIntentados</th>\n",
       "      <th>TirosLibresPorcentaje</th>\n",
       "      <th>RebotesOfensivos</th>\n",
       "      <th>RebotesDefensivos</th>\n",
       "      <th>Rebotes</th>\n",
       "      <th>Asistencias</th>\n",
       "      <th>Robos</th>\n",
       "      <th>Bloqueos</th>\n",
       "      <th>PerdidaBalon</th>\n",
       "      <th>Permanencia</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nombre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Brandon Ingram</th>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrew Harrison</th>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JaKarr Sampson</th>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malik Sealy</th>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matt Geiger</th>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PartidosJugados  MinutosJugados  PuntosPorJuego  \\\n",
       "Nombre                                                             \n",
       "Brandon Ingram                36            27.4             7.4   \n",
       "Andrew Harrison               35            26.9             7.2   \n",
       "JaKarr Sampson                74            15.3             5.2   \n",
       "Malik Sealy                   58            11.6             5.7   \n",
       "Matt Geiger                   48            11.5             4.5   \n",
       "\n",
       "                 PuntosCampoAnotados  PuntosCampoIntentados  \\\n",
       "Nombre                                                        \n",
       "Brandon Ingram                   2.6                    7.6   \n",
       "Andrew Harrison                  2.0                    6.7   \n",
       "JaKarr Sampson                   2.0                    4.7   \n",
       "Malik Sealy                      2.3                    5.5   \n",
       "Matt Geiger                      1.6                    3.0   \n",
       "\n",
       "                 PuntosCampoPorcentaje  Puntos3Anotados  Puntos3Intentados  \\\n",
       "Nombre                                                                       \n",
       "Brandon Ingram                    34.7              0.5                2.1   \n",
       "Andrew Harrison                   29.6              0.7                2.8   \n",
       "JaKarr Sampson                    42.2              0.4                1.7   \n",
       "Malik Sealy                       42.6              0.1                0.5   \n",
       "Matt Geiger                       52.4              0.0                0.1   \n",
       "\n",
       "                 Puntos3Porcentaje  TirosLibresRealizados  \\\n",
       "Nombre                                                      \n",
       "Brandon Ingram                25.0                    1.6   \n",
       "Andrew Harrison               23.5                    2.6   \n",
       "JaKarr Sampson                24.4                    0.9   \n",
       "Malik Sealy                   22.6                    0.9   \n",
       "Matt Geiger                    0.0                    1.3   \n",
       "\n",
       "                 TirosLibresIntentados  TirosLibresPorcentaje  \\\n",
       "Nombre                                                          \n",
       "Brandon Ingram                     2.3                   69.9   \n",
       "Andrew Harrison                    3.4                   76.5   \n",
       "JaKarr Sampson                     1.3                   67.0   \n",
       "Malik Sealy                        1.3                   68.9   \n",
       "Matt Geiger                        1.9                   67.4   \n",
       "\n",
       "                 RebotesOfensivos  RebotesDefensivos  Rebotes  Asistencias  \\\n",
       "Nombre                                                                       \n",
       "Brandon Ingram                0.7                3.4      4.1          1.9   \n",
       "Andrew Harrison               0.5                2.0      2.4          3.7   \n",
       "JaKarr Sampson                0.5                1.7      2.2          1.0   \n",
       "Malik Sealy                   1.0                0.9      1.9          0.8   \n",
       "Matt Geiger                   1.0                1.5      2.5          0.3   \n",
       "\n",
       "                 Robos  Bloqueos  PerdidaBalon  Permanencia  \n",
       "Nombre                                                       \n",
       "Brandon Ingram     0.4       0.4           1.3            0  \n",
       "Andrew Harrison    1.1       0.5           1.6            0  \n",
       "JaKarr Sampson     0.5       0.3           1.0            0  \n",
       "Malik Sealy        0.6       0.1           1.0            1  \n",
       "Matt Geiger        0.3       0.4           0.8            1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_novatos.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8513982-2035-4a54-aa3c-9e417ade9991",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet1 = MLPClassifier(hidden_layer_sizes = (5,5,5),\n",
    "                      activation = \"logistic\",\n",
    "                      solver = \"sgd\",\n",
    "                      random_state = 0)\n",
    "\n",
    "nnet2 = MLPClassifier(hidden_layer_sizes = (50,25,15,10,5),\n",
    "                      activation = \"tanh\",\n",
    "                      solver = \"lbfgs\",\n",
    "                      random_state = 0)\n",
    "\n",
    "### 2 modelos con datos estandarizados.\n",
    "\n",
    "analisis_1_std = Analisis_Predictivo(datos_novatos_std,\n",
    "                                 predecir = \"Permanencia\",\n",
    "                                 modelo = nnet1, \n",
    "                                 train_size = 0.7,\n",
    "                                 random_state = 0)\n",
    "\n",
    "analisis_2_std = Analisis_Predictivo(datos_novatos_std,\n",
    "                                 predecir = \"Permanencia\",\n",
    "                                 modelo = nnet2, \n",
    "                                 train_size = 0.7,\n",
    "                                 random_state = 0)\n",
    "\n",
    "resultados_1 = analisis_1_std.fit_predict_resultados(imprimir = False)\n",
    "\n",
    "resultados_2 = analisis_2_std.fit_predict_resultados(imprimir = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c9d971-dd35-4363-a42a-8a34c5458a29",
   "metadata": {},
   "source": [
    "Ahora, hacemos lo mismo con los datos sin estandarizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4fca3f2-76ad-412a-a380-bf1d4837cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet3 = MLPClassifier(hidden_layer_sizes = (5,5,5),\n",
    "                      activation = \"logistic\",\n",
    "                      solver = \"sgd\",\n",
    "                      random_state = 0)\n",
    "\n",
    "nnet4 = MLPClassifier(hidden_layer_sizes = (50,25,15,10,5),\n",
    "                      activation = \"tanh\",\n",
    "                      solver = \"lbfgs\",\n",
    "                      random_state = 0)\n",
    "\n",
    "### 2 modelos con datos NO estandarizados.\n",
    "\n",
    "analisis_3 = Analisis_Predictivo(datos_novatos,\n",
    "                                 predecir = \"Permanencia\",\n",
    "                                 modelo = nnet3, \n",
    "                                 train_size = 0.75,\n",
    "                                 random_state = 0)\n",
    "\n",
    "analisis_4 = Analisis_Predictivo(datos_novatos,\n",
    "                                 predecir = \"Permanencia\",\n",
    "                                 modelo = nnet4, \n",
    "                                 train_size = 0.75,\n",
    "                                 random_state = 0)\n",
    "\n",
    "resultados_3 = analisis_3.fit_predict_resultados(imprimir = False)\n",
    "\n",
    "resultados_4 = analisis_4.fit_predict_resultados(imprimir = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dcef46b-8749-4474-9597-4561771d70cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precisión Global</th>\n",
       "      <th>Error Global</th>\n",
       "      <th>Precisión Positiva (PP)</th>\n",
       "      <th>Precisión Negativa (PN)</th>\n",
       "      <th>Proporción de Falsos Positivos (PFP)</th>\n",
       "      <th>Proporción de Falsos Negativos (PFN)</th>\n",
       "      <th>Asertividad Positiva (AP)</th>\n",
       "      <th>Asertividad Negativa (AN)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nnet 1 estandarizado</th>\n",
       "      <td>0.395990</td>\n",
       "      <td>0.604010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.395990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nnet 2 estandarizado</th>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.634085</td>\n",
       "      <td>0.269710</td>\n",
       "      <td>0.512658</td>\n",
       "      <td>0.487342</td>\n",
       "      <td>0.730290</td>\n",
       "      <td>0.457746</td>\n",
       "      <td>0.315175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nnet 1 NO estandarizado</th>\n",
       "      <td>0.384384</td>\n",
       "      <td>0.615616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.384384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nnet 2 NO estandarizado</th>\n",
       "      <td>0.336336</td>\n",
       "      <td>0.663664</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.601562</td>\n",
       "      <td>0.398438</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.406977</td>\n",
       "      <td>0.311741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Precisión Global  Error Global  \\\n",
       "Nnet 1 estandarizado             0.395990      0.604010   \n",
       "Nnet 2 estandarizado             0.365915      0.634085   \n",
       "Nnet 1 NO estandarizado          0.384384      0.615616   \n",
       "Nnet 2 NO estandarizado          0.336336      0.663664   \n",
       "\n",
       "                         Precisión Positiva (PP)  Precisión Negativa (PN)  \\\n",
       "Nnet 1 estandarizado                    0.000000                 1.000000   \n",
       "Nnet 2 estandarizado                    0.269710                 0.512658   \n",
       "Nnet 1 NO estandarizado                 0.000000                 1.000000   \n",
       "Nnet 2 NO estandarizado                 0.170732                 0.601562   \n",
       "\n",
       "                         Proporción de Falsos Positivos (PFP)  \\\n",
       "Nnet 1 estandarizado                                 0.000000   \n",
       "Nnet 2 estandarizado                                 0.487342   \n",
       "Nnet 1 NO estandarizado                              0.000000   \n",
       "Nnet 2 NO estandarizado                              0.398438   \n",
       "\n",
       "                         Proporción de Falsos Negativos (PFN)  \\\n",
       "Nnet 1 estandarizado                                 1.000000   \n",
       "Nnet 2 estandarizado                                 0.730290   \n",
       "Nnet 1 NO estandarizado                              1.000000   \n",
       "Nnet 2 NO estandarizado                              0.829268   \n",
       "\n",
       "                         Asertividad Positiva (AP)  Asertividad Negativa (AN)  \n",
       "Nnet 1 estandarizado                           NaN                   0.395990  \n",
       "Nnet 2 estandarizado                      0.457746                   0.315175  \n",
       "Nnet 1 NO estandarizado                        NaN                   0.384384  \n",
       "Nnet 2 NO estandarizado                   0.406977                   0.311741  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparacion_df = pd.DataFrame({})\n",
    "resultados = [resultados_1, resultados_2, resultados_3, resultados_4]\n",
    "\n",
    "for res in resultados:\n",
    "    \n",
    "    medidas = MatConf(res['Matriz de Confusión']).dict_medidas\n",
    "    comp_res = pd.DataFrame({})\n",
    "\n",
    "    for key in list(medidas.keys()):\n",
    "        comp_res[key] = [medidas[key]]\n",
    "    comparacion_df = comparacion_df.append(comp_res, ignore_index=True)\n",
    "\n",
    "comparacion_df.index = ['Nnet 1 estandarizado', 'Nnet 2 estandarizado',\n",
    "                       'Nnet 1 NO estandarizado', 'Nnet 2 NO estandarizado']\n",
    "comparacion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaacc05-30fe-4641-92d4-e9c97a6ca114",
   "metadata": {},
   "source": [
    "En este caso, vemos que los modelos tienen un comportamiento similar, pero esto es quizá por una inapropiada escogencia de arquitecturas para nuestras redes neuronales. \n",
    "Sí podemos notar, sin embargo, que la precisión global es ligeramente mayor en los casos que utilizan los datos estandarizados, para cada modelo correspondiente. Lo cual era de esperar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f44c224-2e9b-469a-81fc-92b11b399a77",
   "metadata": {},
   "source": [
    "<div class='question_container'>\n",
    "    <h2> Pregunta 2 </h2>\n",
    "    <p>Este conjunto de datos es originalmente del Instituto Nacional de Diabetes y Enfermedades Digestivas y Renales. El objetivo del conjunto de datos es predecir de forma diagnóstica si un paciente tiene diabetes o no, basándose en determinadas medidas de diagnóstico incluidas en el conjunto de datos. El conjunto de datos tiene 390 filas y 16 columnas: </p>\n",
    "    <ul>\n",
    "        <li><code>X</code>: Id del paciente.</li>\n",
    "        <li><code>colesterol</code>: Colesterol en mg/dL.</li>\n",
    "        <li><code>glucosa</code>: Glucosa en mg/dL.</li>\n",
    "        <li><code>hdl_col</code>: Lipoproteínas (colesterol bueno).</li>\n",
    "        <li><code>prop_col_hdl</code>: Proporción del colesterol entre el hdl.</li>\n",
    "        <li><code>edad</code>: Edad del paciente.</li>\n",
    "        <li><code>genero</code>: Género del paciente.</li>\n",
    "        <li><code>altura</code>: Altura en pulgadas del paciente.</li>\n",
    "        <li><code>peso</code>: Peso en libras del paciente.</li>\n",
    "        <li><code>IMC</code>: índice de masa corporal.</li>\n",
    "        <li><code>ps_sistolica</code>: Presión arterial sistólica.</li>\n",
    "        <li><code>ps_diastolica</code>: Presión arterial diastólica.</li>\n",
    "        <li><code>cintura</code>: Longitud de la cintura en pulgadas.</li>\n",
    "        <li><code>cadera</code>: Longitud de la cadera en pulgadas.</li>\n",
    "        <li><code>prop_cin_cad</code>: Proporción de la longitud de la cintura entre la longitud de la cadera.</li>\n",
    "        <li><code>diabetes</code>: Diagnóstico de la diabetes.</li>\n",
    "    </ul>\n",
    "    <p>Realice lo siguiente:</p>\n",
    "    <ul>\n",
    "    <li> Cargue en <code>Python</code> la tabla de datos <code>diabetes.csv</code>.</li>\n",
    "    <li> Usando el paquete <code>MLPClassifier</code> en <code>Python</code> genere modelos predictivos usando un 75% de los datos para tabla aprendizaje y un 25% para la tabla testing. Genere al menos 2 modelos con configuraciones diferentes en los parámetros vistos en clase (<code>hidden_layer_sizes</code>, <code>activation</code>, <code>solver</code>). Realice lo anterior sin estandarizar los datos y luego con los datos estandarizados, es decir, al menos 4 modelos. Para estandarizar los datos utilice la clase <code>StandardScaler</code> de <code>sklearn.preprocessing</code> </li>\n",
    "        <li>Para cada modelo obtenga los índices de precisión, compare e interprete los resultados y las diferencias entre los modelos con datos estandarizados y los que no.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "baa5ae9b-8aec-4e9c-ae1d-5c7f89b9b47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    228\n",
       "male      162\n",
       "Name: genero, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_diabetes = pd.read_csv(\"diabetes.csv\",index_col=0)\n",
    "datos_diabetes['genero'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1cbf0011-2f1a-4939-acf0-1c533b503e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colesterol         int64\n",
       "glucosa            int64\n",
       "hdl_chol           int64\n",
       "prop_col_hdl     float64\n",
       "edad               int64\n",
       "genero            object\n",
       "altura             int64\n",
       "peso               int64\n",
       "IMC              float64\n",
       "ps_sistolica       int64\n",
       "ps_diastolica      int64\n",
       "cintura            int64\n",
       "caderas            int64\n",
       "prop_cin_cad     float64\n",
       "diabetes          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_diabetes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f16ae0-2150-4938-804a-84d4b973d935",
   "metadata": {},
   "source": [
    "La variable `genero` es categórica, así que la convertiremos a dummy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8dd7f0cf-e5de-4d71-9351-8055213c6112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colesterol</th>\n",
       "      <th>glucosa</th>\n",
       "      <th>hdl_chol</th>\n",
       "      <th>prop_col_hdl</th>\n",
       "      <th>edad</th>\n",
       "      <th>altura</th>\n",
       "      <th>peso</th>\n",
       "      <th>IMC</th>\n",
       "      <th>ps_sistolica</th>\n",
       "      <th>ps_diastolica</th>\n",
       "      <th>cintura</th>\n",
       "      <th>caderas</th>\n",
       "      <th>prop_cin_cad</th>\n",
       "      <th>genero_female</th>\n",
       "      <th>genero_male</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>193</td>\n",
       "      <td>77</td>\n",
       "      <td>49</td>\n",
       "      <td>3.9</td>\n",
       "      <td>19</td>\n",
       "      <td>61</td>\n",
       "      <td>119</td>\n",
       "      <td>22.5</td>\n",
       "      <td>118</td>\n",
       "      <td>70</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No_diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146</td>\n",
       "      <td>79</td>\n",
       "      <td>41</td>\n",
       "      <td>3.6</td>\n",
       "      <td>19</td>\n",
       "      <td>60</td>\n",
       "      <td>135</td>\n",
       "      <td>26.4</td>\n",
       "      <td>108</td>\n",
       "      <td>58</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No_diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217</td>\n",
       "      <td>75</td>\n",
       "      <td>54</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20</td>\n",
       "      <td>67</td>\n",
       "      <td>187</td>\n",
       "      <td>29.3</td>\n",
       "      <td>110</td>\n",
       "      <td>72</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No_diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>226</td>\n",
       "      <td>97</td>\n",
       "      <td>70</td>\n",
       "      <td>3.2</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>114</td>\n",
       "      <td>19.6</td>\n",
       "      <td>122</td>\n",
       "      <td>64</td>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No_diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>164</td>\n",
       "      <td>91</td>\n",
       "      <td>67</td>\n",
       "      <td>2.4</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>141</td>\n",
       "      <td>20.2</td>\n",
       "      <td>122</td>\n",
       "      <td>86</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No_diabetes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   colesterol  glucosa  hdl_chol  prop_col_hdl  edad  altura  peso   IMC  \\\n",
       "1         193       77        49           3.9    19      61   119  22.5   \n",
       "2         146       79        41           3.6    19      60   135  26.4   \n",
       "3         217       75        54           4.0    20      67   187  29.3   \n",
       "4         226       97        70           3.2    20      64   114  19.6   \n",
       "5         164       91        67           2.4    20      70   141  20.2   \n",
       "\n",
       "   ps_sistolica  ps_diastolica  cintura  caderas  prop_cin_cad  genero_female  \\\n",
       "1           118             70       32       38          0.84              1   \n",
       "2           108             58       33       40          0.83              1   \n",
       "3           110             72       40       45          0.89              1   \n",
       "4           122             64       31       39          0.79              1   \n",
       "5           122             86       32       39          0.82              1   \n",
       "\n",
       "   genero_male     diabetes  \n",
       "1            0  No_diabetes  \n",
       "2            0  No_diabetes  \n",
       "3            0  No_diabetes  \n",
       "4            0  No_diabetes  \n",
       "5            0  No_diabetes  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convertimos a Dummy algunas de las variables predictoras\n",
    "datos_diabetes_dum = pd.get_dummies(datos_diabetes, columns=['genero'])\n",
    "col_diat = datos_diabetes_dum.pop(\"diabetes\")\n",
    "datos_diabetes_dum.insert(15, \"diabetes\", col_diat )\n",
    "datos_diabetes_dum.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24e191fa-a946-4e25-99bb-77581b5f98e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colesterol</th>\n",
       "      <th>glucosa</th>\n",
       "      <th>hdl_chol</th>\n",
       "      <th>prop_col_hdl</th>\n",
       "      <th>edad</th>\n",
       "      <th>altura</th>\n",
       "      <th>peso</th>\n",
       "      <th>IMC</th>\n",
       "      <th>ps_sistolica</th>\n",
       "      <th>ps_diastolica</th>\n",
       "      <th>cintura</th>\n",
       "      <th>caderas</th>\n",
       "      <th>prop_cin_cad</th>\n",
       "      <th>genero_female</th>\n",
       "      <th>genero_male</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.319013</td>\n",
       "      <td>-0.564655</td>\n",
       "      <td>-0.073401</td>\n",
       "      <td>-0.360132</td>\n",
       "      <td>-1.692029</td>\n",
       "      <td>-1.265070</td>\n",
       "      <td>-1.447312</td>\n",
       "      <td>-0.951944</td>\n",
       "      <td>-0.838071</td>\n",
       "      <td>-0.985822</td>\n",
       "      <td>-1.020105</td>\n",
       "      <td>-0.882489</td>\n",
       "      <td>-0.565995</td>\n",
       "      <td>0.842927</td>\n",
       "      <td>-0.842927</td>\n",
       "      <td>No_diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.372619</td>\n",
       "      <td>-0.527432</td>\n",
       "      <td>-0.536983</td>\n",
       "      <td>-0.533102</td>\n",
       "      <td>-1.692029</td>\n",
       "      <td>-1.520574</td>\n",
       "      <td>-1.050840</td>\n",
       "      <td>-0.360358</td>\n",
       "      <td>-1.276087</td>\n",
       "      <td>-1.875972</td>\n",
       "      <td>-0.846299</td>\n",
       "      <td>-0.528950</td>\n",
       "      <td>-0.702760</td>\n",
       "      <td>0.842927</td>\n",
       "      <td>-0.842927</td>\n",
       "      <td>No_diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.218998</td>\n",
       "      <td>-0.601879</td>\n",
       "      <td>0.216339</td>\n",
       "      <td>-0.302476</td>\n",
       "      <td>-1.631108</td>\n",
       "      <td>0.267951</td>\n",
       "      <td>0.237692</td>\n",
       "      <td>0.079539</td>\n",
       "      <td>-1.188484</td>\n",
       "      <td>-0.837464</td>\n",
       "      <td>0.370339</td>\n",
       "      <td>0.354899</td>\n",
       "      <td>0.117828</td>\n",
       "      <td>0.842927</td>\n",
       "      <td>-0.842927</td>\n",
       "      <td>No_diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.420753</td>\n",
       "      <td>-0.192418</td>\n",
       "      <td>1.143504</td>\n",
       "      <td>-0.763729</td>\n",
       "      <td>-1.631108</td>\n",
       "      <td>-0.498560</td>\n",
       "      <td>-1.571209</td>\n",
       "      <td>-1.391841</td>\n",
       "      <td>-0.662865</td>\n",
       "      <td>-1.430897</td>\n",
       "      <td>-1.193910</td>\n",
       "      <td>-0.705719</td>\n",
       "      <td>-1.249818</td>\n",
       "      <td>0.842927</td>\n",
       "      <td>-0.842927</td>\n",
       "      <td>No_diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.969111</td>\n",
       "      <td>-0.304089</td>\n",
       "      <td>0.969660</td>\n",
       "      <td>-1.224982</td>\n",
       "      <td>-1.631108</td>\n",
       "      <td>1.034462</td>\n",
       "      <td>-0.902163</td>\n",
       "      <td>-1.300828</td>\n",
       "      <td>-0.662865</td>\n",
       "      <td>0.201045</td>\n",
       "      <td>-1.020105</td>\n",
       "      <td>-0.705719</td>\n",
       "      <td>-0.839524</td>\n",
       "      <td>0.842927</td>\n",
       "      <td>-0.842927</td>\n",
       "      <td>No_diabetes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   colesterol   glucosa  hdl_chol  prop_col_hdl      edad    altura      peso  \\\n",
       "1   -0.319013 -0.564655 -0.073401     -0.360132 -1.692029 -1.265070 -1.447312   \n",
       "2   -1.372619 -0.527432 -0.536983     -0.533102 -1.692029 -1.520574 -1.050840   \n",
       "3    0.218998 -0.601879  0.216339     -0.302476 -1.631108  0.267951  0.237692   \n",
       "4    0.420753 -0.192418  1.143504     -0.763729 -1.631108 -0.498560 -1.571209   \n",
       "5   -0.969111 -0.304089  0.969660     -1.224982 -1.631108  1.034462 -0.902163   \n",
       "\n",
       "        IMC  ps_sistolica  ps_diastolica   cintura   caderas  prop_cin_cad  \\\n",
       "1 -0.951944     -0.838071      -0.985822 -1.020105 -0.882489     -0.565995   \n",
       "2 -0.360358     -1.276087      -1.875972 -0.846299 -0.528950     -0.702760   \n",
       "3  0.079539     -1.188484      -0.837464  0.370339  0.354899      0.117828   \n",
       "4 -1.391841     -0.662865      -1.430897 -1.193910 -0.705719     -1.249818   \n",
       "5 -1.300828     -0.662865       0.201045 -1.020105 -0.705719     -0.839524   \n",
       "\n",
       "   genero_female  genero_male     diabetes  \n",
       "1       0.842927    -0.842927  No_diabetes  \n",
       "2       0.842927    -0.842927  No_diabetes  \n",
       "3       0.842927    -0.842927  No_diabetes  \n",
       "4       0.842927    -0.842927  No_diabetes  \n",
       "5       0.842927    -0.842927  No_diabetes  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_diabetes_dum_std = datos_diabetes_dum.copy()\n",
    "datos_diabetes_dum_std.iloc[:,0:15] = StandardScaler().fit_transform(datos_diabetes_dum_std.iloc[:,0:15])\n",
    "datos_diabetes_dum_std.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2ebde8-90dd-4a63-bfbb-59a6532a9341",
   "metadata": {},
   "source": [
    "Procedemos a hacer lo mismo que en el ejercicio anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dfab0def-7b89-44c9-a2fb-dc36acad1b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet1 = MLPClassifier(hidden_layer_sizes = (3,)*4, activation = \"relu\",\n",
    "                      solver = \"adam\", random_state = 0)\n",
    "\n",
    "nnet2 = MLPClassifier(hidden_layer_sizes = (100,50,30,10), activation = \"identity\",\n",
    "                      solver = \"lbfgs\", random_state = 0)\n",
    "\n",
    "### 2 modelos con datos estandarizados.\n",
    "analisis_1 = Analisis_Predictivo(datos_diabetes_dum_std, predecir = \"diabetes\",\n",
    "                                 modelo = nnet1, train_size = 0.75, random_state = 40)\n",
    "\n",
    "analisis_2 = Analisis_Predictivo(datos_diabetes_dum_std, predecir = \"diabetes\",\n",
    "                                 modelo = nnet2, train_size = 0.75, random_state = 40)\n",
    "\n",
    "resultados_1 = analisis_1.fit_predict_resultados(imprimir = False)\n",
    "resultados_2 = analisis_2.fit_predict_resultados(imprimir = False)\n",
    "\n",
    "nnet3 = MLPClassifier(hidden_layer_sizes = (3,)*4, activation = \"relu\", \n",
    "                      solver = \"adam\", random_state = 0)\n",
    "\n",
    "nnet4 = MLPClassifier(hidden_layer_sizes = (100,50,30,10), activation = \"identity\",\n",
    "                      solver = \"lbfgs\", random_state = 0)\n",
    "\n",
    "\n",
    "analisis_3 = Analisis_Predictivo(datos_diabetes_dum, predecir = \"diabetes\",\n",
    "                                 modelo = nnet3, train_size = 0.75, random_state = 40)\n",
    "\n",
    "analisis_4 = Analisis_Predictivo(datos_diabetes_dum, predecir = \"diabetes\",\n",
    "                                 modelo = nnet4, train_size = 0.75, random_state = 40)\n",
    "\n",
    "resultados_3 = analisis_3.fit_predict_resultados(imprimir = False)\n",
    "resultados_4 = analisis_4.fit_predict_resultados(imprimir = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15b92c38-2596-48b0-8289-bf2c3c23526d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precisión Global</th>\n",
       "      <th>Error Global</th>\n",
       "      <th>Precisión Positiva (PP)</th>\n",
       "      <th>Precisión Negativa (PN)</th>\n",
       "      <th>Proporción de Falsos Positivos (PFP)</th>\n",
       "      <th>Proporción de Falsos Negativos (PFN)</th>\n",
       "      <th>Asertividad Positiva (AP)</th>\n",
       "      <th>Asertividad Negativa (AN)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nnet 1 estandarizado</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.921348</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>0.921348</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nnet 2 estandarizado</th>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nnet 1 NO estandarizado</th>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.908163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.091837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nnet 2 NO estandarizado</th>\n",
       "      <td>0.908163</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.908163</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Precisión Global  Error Global  \\\n",
       "Nnet 1 estandarizado             0.857143      0.142857   \n",
       "Nnet 2 estandarizado             0.948980      0.051020   \n",
       "Nnet 1 NO estandarizado          0.091837      0.908163   \n",
       "Nnet 2 NO estandarizado          0.908163      0.091837   \n",
       "\n",
       "                         Precisión Positiva (PP)  Precisión Negativa (PN)  \\\n",
       "Nnet 1 estandarizado                    0.921348                 0.222222   \n",
       "Nnet 2 estandarizado                    0.977528                 0.666667   \n",
       "Nnet 1 NO estandarizado                 0.000000                 1.000000   \n",
       "Nnet 2 NO estandarizado                 1.000000                 0.000000   \n",
       "\n",
       "                         Proporción de Falsos Positivos (PFP)  \\\n",
       "Nnet 1 estandarizado                                 0.777778   \n",
       "Nnet 2 estandarizado                                 0.333333   \n",
       "Nnet 1 NO estandarizado                              0.000000   \n",
       "Nnet 2 NO estandarizado                              1.000000   \n",
       "\n",
       "                         Proporción de Falsos Negativos (PFN)  \\\n",
       "Nnet 1 estandarizado                                 0.078652   \n",
       "Nnet 2 estandarizado                                 0.022472   \n",
       "Nnet 1 NO estandarizado                              1.000000   \n",
       "Nnet 2 NO estandarizado                              0.000000   \n",
       "\n",
       "                         Asertividad Positiva (AP)  Asertividad Negativa (AN)  \n",
       "Nnet 1 estandarizado                      0.921348                   0.222222  \n",
       "Nnet 2 estandarizado                      0.966667                   0.750000  \n",
       "Nnet 1 NO estandarizado                        NaN                   0.091837  \n",
       "Nnet 2 NO estandarizado                   0.908163                        NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparacion_df = pd.DataFrame({})\n",
    "resultados = [resultados_1, resultados_2, resultados_3, resultados_4]\n",
    "\n",
    "for res in resultados:\n",
    "    \n",
    "    medidas = MatConf(res['Matriz de Confusión']).dict_medidas\n",
    "    comp_res = pd.DataFrame({})\n",
    "\n",
    "    for key in list(medidas.keys()):\n",
    "        comp_res[key] = [medidas[key]]\n",
    "    comparacion_df = comparacion_df.append(comp_res, ignore_index=True)\n",
    "\n",
    "comparacion_df.index = ['Nnet 1 estandarizado', 'Nnet 2 estandarizado',\n",
    "                       'Nnet 1 NO estandarizado', 'Nnet 2 NO estandarizado']\n",
    "comparacion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02b7c6-a1fb-44ca-83fd-4abfe250e2be",
   "metadata": {},
   "source": [
    "Observe que para esta selección particular de parámetros y arquitecturas tuvimos un comportamiento superior en con los datos estandarizados. Algún fenómeno sucedió con la segunda arquitectura en los datos no estandarizados. Posiblemente de naturaleza numérica al emplear el solver y la función de activación seleccionados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b60ff8c-7cbe-4346-a913-5cd8c5f28f19",
   "metadata": {},
   "source": [
    "<div class='question_container'>\n",
    "    <h2> Pregunta 3 </h2>\n",
    "    <p>En este ejercicio vamos a predecir números escritos a mano (Hand Written Digit Recognition), la tabla de aprendizaje está en el archivo `ZipDataTrainCod.csv` y la tabla de testing está en el archivo `ZipDataTestCod.csv`. En la figura siguiente se ilustran los datos: </p>\n",
    "    <p> Los datos de este ejemplo vienen de los códigos postales escritos a mano en sobres del correo postal de EE.UU. Las imágenes son de 16 $\\times$ 16 en escala de grises, cada pixel va de intensidad de -1 a 1 (de blanco a negro). Las imágenes se han normalizado para tener aproximadamente el mismo tamaño y orientación. La tarea consiste en predecir, a partir de la matriz de 16 $\\times$ 16 de intensidades de cada pixel, la identidad de cada imagen (0, 1, ...,  9) de forma rápida y precisa. Si es lo suficientemente precisa, el algoritmo resultante se utiliza como parte de un procedimiento de selección automática para sobres. Este es un problema de clasificación para el cual la tasa de error debe mantenerse muy baja para evitar la mala dirección de correo. La columna 1 tiene la variable a predecir Número codificada como sigue: 0='cero'; 1='uno'; 2='dos'; 3='tres'; 4='cuatro'; 5='cinco';6='seis'; 7='siete'; 8='ocho' y 9='nueve', las demás columnas son las variables predictivas, además cada fila de la tabla representa un bloque 16 $\\times$ 16 por lo que la matriz tiene 256 variables predictoras. </p>\n",
    "    <ol>\n",
    "        <li>Usando el paquete <code>MLPClassifier</code> en <code>Python</code> genere un modelo predictivo de redes neuronales para estos datos. Utilice los siguientes parámetros: <code>hidden_layer_sizes = (250,100,50,25)</code>, <code>max_iter = 50000</code>, <code>activation = 'relu'</code>, <code>solver = 'adam'</code>, <code>random_state=0</code>. Interprete los resultados. </li>\n",
    "        <li>Genere un modelo de redes neuronales con los mismos parámetros del ítem anterior, pero esta vez reemplace cada bloque $4\\times4$ de píxeles por su promedio. ¿Mejora la predicción? ¿Qué ventaja tiene estos datos respecto a los anteriores? Recuerde que cada bloque $16\\times16$ está representado por una fila en las matrices de aprendizaje y testing. Despliegue la matriz de confusión resultante. La matriz de confusión obtenida debería ser igual o muy similar a ésta (ver enunciado). </li>\n",
    "        <li>Repita el item anterior pero esta vez reemplace cada bloque $4\\times 4$ de píxeles por el máximo. ¿Mejoran resultados respecto a usar el promedio de cada bloque?</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acf28648-76dc-46dc-9b8d-a3cbd7aed18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipdata_train = pd.read_csv(\"ZipDataTrainCod.csv\",sep=';')\n",
    "zipdata_test = pd.read_csv(\"ZipDataTestCod.csv\",sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d35611ee-c357-4ec1-a28a-c64bd5627dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = zipdata_train.drop(['Numero'],axis=1)\n",
    "y_train = zipdata_train['Numero']\n",
    "X_test = zipdata_test.drop(['Numero'],axis=1)\n",
    "y_test = zipdata_test['Numero']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c99581c-45a6-4a87-a681-cd88ed532461",
   "metadata": {},
   "source": [
    "Ajustamos ahora la red neuronal solicitada sobre estos datos. Por el momento, no vamos a estandarizar los datos, aunque sería posible hacerlo en este ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71b55072-9ec1-4247-a520-a7f8a972485a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(250, 100, 50, 25), max_iter=50000,\n",
       "              random_state=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet = MLPClassifier(\n",
    "    hidden_layer_sizes = (250,100,50,25),\n",
    "    max_iter = 50000,\n",
    "    activation = 'relu',\n",
    "    solver = 'adam', \n",
    "    random_state=0) #Parametros indicados en la tarea\n",
    "\n",
    "nnet.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e38a0-a29c-426d-b15c-b0ad0400d6b2",
   "metadata": {},
   "source": [
    "Obtenemos nuestra matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d6877e5-dd90-4c01-a5a1-f72b445a344f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[352,   0,   3,   2,   1,   0,   1,   0,   0,   0],\n",
       "       [  3, 147,   0,   1,   3,   1,   0,   0,   5,   0],\n",
       "       [  1,   2, 187,   2,   4,   0,   2,   0,   0,   2],\n",
       "       [  3,   0,   2, 181,   0,   6,   1,   2,   3,   0],\n",
       "       [  0,   1,   6,   0, 169,   0,   0,   1,   0,   0],\n",
       "       [  4,   1,   3,   2,   1, 150,   0,   1,   4,   0],\n",
       "       [  0,   1,   2,   3,   0,   1, 163,   0,   0,   0],\n",
       "       [  0,   0,   7,   1,   2,   1,   0, 136,   0,   0],\n",
       "       [  1,   9,   0,   3,   0,   4,   0,   0, 149,   0],\n",
       "       [  0,   0,   4,   1,   1,   1,   3,   0,   1, 253]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion = nnet.predict(X_test)\n",
    "mat_cfn = confusion_matrix(y_test, prediccion)\n",
    "mat_cfn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607bdb34-cb71-4921-8d7d-8009076fb7bb",
   "metadata": {},
   "source": [
    "Encontramos la precisión por cada dígito. Para esto reciclamos una función de la Tarea 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6e61fb1f-c93c-45c0-bb11-c893bf35b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prec_multi(mat_cfn, labels):\n",
    "    suma_total = sum(sum(mat_cfn))\n",
    "    suma_diag = sum([mat_cfn[i,i] for i in range(mat_cfn.shape[0])])\n",
    "    prec_global = suma_diag/suma_total\n",
    "    err_global = 1- prec_global\n",
    "    prec_digitos={} ### Creamos un diccionario con la precisión de cada dígito.\n",
    "    prec_digitos['Precisión Global']=prec_global\n",
    "    prec_digitos['Error Global']=err_global\n",
    "    for i in range(mat_cfn.shape[0]):\n",
    "        prec_este_digito = mat_cfn[i,i]/sum([mat_cfn[i,j] for j in range(mat_cfn.shape[0])])\n",
    "        prec_digitos[f'Precisión \"{labels[i]}\"']= prec_este_digito\n",
    "    return prec_digitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6de0a165-c2a1-46a4-80e6-0a2aa5fe63f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precisión Global': 0.9402092675635276,\n",
       " 'Error Global': 0.05979073243647237,\n",
       " 'Precisión \"cero\"': 0.9805013927576601,\n",
       " 'Precisión \"cinco\"': 0.91875,\n",
       " 'Precisión \"cuatro\"': 0.935,\n",
       " 'Precisión \"dos\"': 0.9141414141414141,\n",
       " 'Precisión \"nueve\"': 0.9548022598870056,\n",
       " 'Precisión \"ocho\"': 0.9036144578313253,\n",
       " 'Precisión \"seis\"': 0.9588235294117647,\n",
       " 'Precisión \"siete\"': 0.9251700680272109,\n",
       " 'Precisión \"tres\"': 0.8975903614457831,\n",
       " 'Precisión \"uno\"': 0.9583333333333334}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dig=['cero','cinco','cuatro','dos','nueve','ocho','seis','siete','tres','uno']\n",
    "get_prec_multi(mat_cfn, labels_dig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ae4dd-3be2-4cf8-a1e3-574c39fb65f8",
   "metadata": {},
   "source": [
    "Tenemos precisiones altas para la mayoría de los dígitos acá."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b93de-ee1d-4779-8859-ae303ce4f556",
   "metadata": {},
   "source": [
    "Seguidamente, haremos algo similar pero haciendo bloques de $4 \\times 4$. Para lograr esto usamos el mismo código empleado en la Tarea 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "13e61207-fcef-4313-9462-3649915c7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hacer_bloques(data,p):\n",
    "    \n",
    "    data_dim = int(math.sqrt(data.shape[1]))\n",
    "    \n",
    "    if data_dim % p == 0:\n",
    "        \n",
    "        q = int(data_dim / p)\n",
    "        data_blocked = {}\n",
    "        for i in range(q):\n",
    "            for j in range(q):\n",
    "                data_blocked[f'V{i}_{j}']=[]\n",
    "        data_blocked = pd.DataFrame({})\n",
    "        \n",
    "        for r in range(data.shape[0]):\n",
    "            ### Hacer un bloque de cada fila ###\n",
    "            fila=data.iloc[r].tolist()\n",
    "            x = np.array(fila)\n",
    "            x = x.reshape(data_dim, data_dim)\n",
    "            data_blocked_fila={}\n",
    "            for i in range(q):\n",
    "                for j in range(q):\n",
    "                    \n",
    "                    bloque=[]\n",
    "                    for k in range(p):\n",
    "                        bloque.append(x[p*i+k][p*j:p*(j+1)])\n",
    "                    bloque=np.array([bloque])\n",
    "                    \n",
    "                    mean_bloque = np.mean(bloque)\n",
    "                    data_blocked_fila[f'V_{i}_{j}']=[mean_bloque]\n",
    "                    \n",
    "            data_blocked_fila = pd.DataFrame(data_blocked_fila)\n",
    "            data_blocked = data_blocked.append(data_blocked_fila, ignore_index=True)\n",
    "                \n",
    "        return data_blocked\n",
    "    else:\n",
    "        raise Exception(\"No se pueden hacer bloques de este tamaño\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9cef672d-45d8-41c9-a4db-b56912f1bc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V_0_0</th>\n",
       "      <th>V_0_1</th>\n",
       "      <th>V_0_2</th>\n",
       "      <th>V_0_3</th>\n",
       "      <th>V_1_0</th>\n",
       "      <th>V_1_1</th>\n",
       "      <th>V_1_2</th>\n",
       "      <th>V_1_3</th>\n",
       "      <th>V_2_0</th>\n",
       "      <th>V_2_1</th>\n",
       "      <th>V_2_2</th>\n",
       "      <th>V_2_3</th>\n",
       "      <th>V_3_0</th>\n",
       "      <th>V_3_1</th>\n",
       "      <th>V_3_2</th>\n",
       "      <th>V_3_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.474625</td>\n",
       "      <td>-0.375938</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.821562</td>\n",
       "      <td>0.193125</td>\n",
       "      <td>-0.717812</td>\n",
       "      <td>-0.804563</td>\n",
       "      <td>-0.008250</td>\n",
       "      <td>-0.009563</td>\n",
       "      <td>0.027188</td>\n",
       "      <td>-0.051063</td>\n",
       "      <td>-0.576125</td>\n",
       "      <td>0.692063</td>\n",
       "      <td>0.627938</td>\n",
       "      <td>-0.785875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.859687</td>\n",
       "      <td>0.531687</td>\n",
       "      <td>0.310500</td>\n",
       "      <td>-0.038937</td>\n",
       "      <td>-0.833000</td>\n",
       "      <td>0.475688</td>\n",
       "      <td>0.214625</td>\n",
       "      <td>-0.871188</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>-0.895750</td>\n",
       "      <td>-0.811813</td>\n",
       "      <td>0.244750</td>\n",
       "      <td>-0.182938</td>\n",
       "      <td>0.228562</td>\n",
       "      <td>0.386750</td>\n",
       "      <td>0.313188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.987500</td>\n",
       "      <td>-0.138437</td>\n",
       "      <td>-0.937500</td>\n",
       "      <td>-0.733625</td>\n",
       "      <td>-0.354875</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>-0.998563</td>\n",
       "      <td>-0.616125</td>\n",
       "      <td>0.111375</td>\n",
       "      <td>0.332375</td>\n",
       "      <td>-0.601938</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.900687</td>\n",
       "      <td>0.170062</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.869625</td>\n",
       "      <td>0.109812</td>\n",
       "      <td>0.074312</td>\n",
       "      <td>-0.647687</td>\n",
       "      <td>-0.667375</td>\n",
       "      <td>-0.701563</td>\n",
       "      <td>-0.093875</td>\n",
       "      <td>-0.848375</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.911438</td>\n",
       "      <td>-0.075313</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.403062</td>\n",
       "      <td>-0.557000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.025062</td>\n",
       "      <td>0.063688</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.238063</td>\n",
       "      <td>0.320750</td>\n",
       "      <td>-0.984812</td>\n",
       "      <td>-0.895563</td>\n",
       "      <td>-0.882188</td>\n",
       "      <td>-0.735688</td>\n",
       "      <td>-0.188812</td>\n",
       "      <td>-0.203000</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.037375</td>\n",
       "      <td>-0.145812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      V_0_0     V_0_1     V_0_2     V_0_3     V_1_0     V_1_1     V_1_2  \\\n",
       "0 -1.000000 -0.474625 -0.375938 -1.000000 -0.821562  0.193125 -0.717812   \n",
       "1 -0.859687  0.531687  0.310500 -0.038937 -0.833000  0.475688  0.214625   \n",
       "2 -1.000000 -0.987500 -0.138437 -0.937500 -0.733625 -0.354875  0.047500   \n",
       "3 -0.869625  0.109812  0.074312 -0.647687 -0.667375 -0.701563 -0.093875   \n",
       "4 -1.000000  0.025062  0.063688 -1.000000 -1.000000 -0.238063  0.320750   \n",
       "\n",
       "      V_1_3     V_2_0     V_2_1     V_2_2     V_2_3     V_3_0     V_3_1  \\\n",
       "0 -0.804563 -0.008250 -0.009563  0.027188 -0.051063 -0.576125  0.692063   \n",
       "1 -0.871188 -0.000250 -0.895750 -0.811813  0.244750 -0.182938  0.228562   \n",
       "2 -0.998563 -0.616125  0.111375  0.332375 -0.601938 -1.000000 -0.900687   \n",
       "3 -0.848375 -1.000000 -0.911438 -0.075313 -1.000000 -1.000000 -0.403062   \n",
       "4 -0.984812 -0.895563 -0.882188 -0.735688 -0.188812 -0.203000  0.169000   \n",
       "\n",
       "      V_3_2     V_3_3  \n",
       "0  0.627938 -0.785875  \n",
       "1  0.386750  0.313188  \n",
       "2  0.170062 -1.000000  \n",
       "3 -0.557000 -1.000000  \n",
       "4  0.037375 -0.145812  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bloques=hacer_bloques(data = X_train, p = 4)\n",
    "data_bloques.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3aad07f9-967a-499c-802b-1e6bb917eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p4 = hacer_bloques(data = X_train, p = 4)\n",
    "X_test_p4 = hacer_bloques(data = X_test, p = 4)\n",
    "y_train_p4 = zipdata_train['Numero']\n",
    "y_test_p4 = zipdata_test['Numero']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26117444-b9ea-42e7-8ffc-a57b124a8fab",
   "metadata": {},
   "source": [
    "Aqui no utilizaré datos estandarizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ad355cd7-1919-4587-a538-997aa086ba8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[343,   1,   1,   2,   0,   6,   2,   2,   0,   2],\n",
       "       [  2, 145,   1,   0,   3,   2,   1,   0,   6,   0],\n",
       "       [  0,   1, 179,   2,  12,   0,   4,   1,   0,   1],\n",
       "       [  4,   5,   2, 175,   1,   5,   2,   1,   3,   0],\n",
       "       [  0,   0,   3,   0, 170,   1,   0,   3,   0,   0],\n",
       "       [  3,   2,   2,   1,   6, 145,   0,   0,   5,   2],\n",
       "       [  8,   1,   2,   1,   0,   0, 157,   0,   0,   1],\n",
       "       [  0,   0,   4,   1,   7,   1,   0, 131,   3,   0],\n",
       "       [  3,  17,   0,   2,   2,   7,   0,   0, 134,   1],\n",
       "       [  1,   1,   3,   1,   0,   5,   3,   2,   1, 247]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet_p4 = MLPClassifier(\n",
    "    hidden_layer_sizes = (250,100,50,25),\n",
    "    max_iter = 50000,\n",
    "    activation = 'relu',\n",
    "    solver = 'adam', \n",
    "    random_state=0) #Parametros indicados en la tarea\n",
    "\n",
    "nnet_p4.fit(X_train_p4.values, y_train_p4)\n",
    "prediccion_p4 = nnet_p4.predict(X_test_p4.values)\n",
    "\n",
    "mat_cfn_p4 = confusion_matrix(y_test, prediccion_p4)\n",
    "mat_cfn_p4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3468d-e920-4707-ae0c-9a0a7218c873",
   "metadata": {},
   "source": [
    "Esta es la matriz de confusión que obtenemos ahora con los datos agrupados en bloques de $4\\times 4$. Tiene una precisión menor para varias clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f1927537-bb48-4caf-9b8d-f87dd64ab6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x188d2175220>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVIAAAEGCAYAAAA3yh0OAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABGuUlEQVR4nO2dd3wVVdrHv78UIIQSQugioCAWRERptgXFrq/u6qq7upZ1195eu6+uuqvuumtb6+5iA8W+iqKigIiC2CiCFCmR3iGUQCCQ3DzvHzOBS0i5yZ1J7oXz/Xzmk7lnzjxz7pnJc8+c8vxkZjgcDoej5qTUdQEcDocj2XGO1OFwOOLEOVKHw+GIE+dIHQ6HI06cI3U4HI44SavrAtQ2Odmp1rF9euB25/7YMHCbDh8pHLtuxkooFFLAdtsW1007eUCm5a2LxJR38o/bRprZKfFcL172OkfasX06349sH7jdk9v2CNxmaCSZY1J6vVDsWnFRKHZDISynH8Kz8F3JZ3HbyFsX4fuR+8aUN7XNvJy4Lxgne50jdTgciY8BJZTUdTFixjlSh8ORcBhGkcX2ap8IOEfqcDgSEtcidTgcjjgwjEgSDQY6R+pwOBKSEpwjTXi2F4pbftWZou0pRIrh2NM3cvFtK3ccf+6edox8M5sPcqcD8NErzflwcA4pKZCRGeHGR5bQ4YBt1brmzY8vps/ATWxYm8aVx3cN5HuEYROgRdvt3PbkYrJyisDEiNea8/6LLeK2e2T/fK56YDmpKcYnb2Tz9jOtAigtZDYp5qa/L6TjAVsx4InbOvHTlEZx2QyrDpKpbsMqa1UYEHGONPFJr2/8452fycgsobgIbj67C72Oz+egI7Ywd1oGmzem7pJ/wC/Xc8bFeQB8M7IJ/7m/HX99fX61rjnqrWyGv5zDbU8uCex7hGETIFIsBv25LbkzGpKRGeGZT+cyZVxjFs9rUGObKSnGtX9dxl0X7MfaFek8PWIe345sGpfNUq66bzGTv2zKQ1d3Ji29hPoZ8fevhVEHYdkNq27DqoNYSKYWadKubJIU14+ABBmZ3j9bcZGIFAkJIhF4/oG2XH7P8l3yZzbe+Y9ZuCWlRtPvZnzXiE3rg/3tCsMmwLrV6eTO8BYZbC1IZcm8+uS0jm/eZdfDt7B8YT1WLq5PcVEKX3yQRb+TN8Zd1oaNizm0zyY+fdObTlhclEJBfvx1EkYdhGU3rLoNqw6qwoAis5i2RCAhWqSSLgZuxau/H4GbgX8DpTNybzKzCZLuB/YH9gMWS7oLeAnIAdYAl5nZ4livG4nAdSd3ZfnCepx56VoO7LmFYS/k0O+kfJq3Kt4t//CXc3hvUAuKtot/vJNb8y+cZLTaZxv7d9vK7B/iW73VvHURa5bvnFy/dkU6B/bcEm/xaN1+Oxvz0rnl0QV0OngrudMb8q/792Xb1tSqT46RoOogLLth1W00YdVBeRiWVK/2dd4ilXQIcA9wvJkdBtwIPAk8YWa9gHOAF6JOORgYaGa/AZ4GhphZd+A14KkKrnGFpEmSJq3J2zk3LTUV/vXZHF6bPIs5Uxsy/dtMxn+YxVm/X1NuWf/nsrUM/uYnLr97Oa8/2Tru754MNGgY4U/PL+Tf97Vjy+bgHFOQpKYanbsV8NHQllx32iEUbknh/GtWBGY/rDpIhrotpdbLahCJcUsE6tyRAscD75jZWgAzWwcMBJ6RNBUYDjSRVDpyMNzMtvr7/YDX/f1XgWPKu4CZDTKzI83syBbNd38IGjWNcNhRm5k2oRHLF9bnsqMO5uLeB7NtawqXHnXQbvn7n72Brz9tWuMvnCykphl/en4hnw9rxoRPsuK2l7cynRZtt+/4nNOmiLUr4o97sHZlPdauqMecqd4jMn5ENp27BdMaC7oOwrIbVt1CeHVQGd7Kpti2RCARHGl5pAB9zayHv7Uzs83+sYIgLrAhL3XHgNK2rWLKuMZ07r6VN6fN5JXvZ/HK97Oon1HC4K9/AmDZ/J2vTd9/1oR2nao3Yp98GDc/tpglufV5b1DLQCzOmdqQdp2206r9NtLSS+h/1ga+HRX/D9L6NemsWVGPffbzfl8PPzqfxfMy4rYbRh2EZTesug2vDqpCRGLcEoFE6CP9HBgm6XEzy5OUDYwCrgceAZDUw8ymlnPu18AFeK3RC4HxsV503ap0Hr1xX0pKREkJHHfmBvqemF9h/uEvt2DK+EakpUGjrGJufTLmrtgd3PncIrr320zT7GKGTprFq4+1YuQbzattJ2ybAIf0KmDgueuZP6sBz42aDcDLD7dl4udNamyzJCKevdub7ZCSCqPezGbR3GBGf5+7rwO3Pzmf9HRjxeL6PH5rp7hthlEHYdkNq27DqoOq8AabEsNJxoISQfxO0iXAbUAE+AFv4OlZ4CA8Zz/OzK7yB5s2m9mj/nkdgJepxmDTkYc1MBf9yUV/Ahf9CQgt+lO+rYvL8CHd69mbH8fWAu6+77LJZnZkPNeLl0RokWJmQ4AhZZLPLyff/WU+L8LrY3U4HHsYJUnUIk0IR+pwOBzReCubnCN1OByOGmOISMKOhe+Oc6QOhyMhca/2DofDEQeG2G6JvUghGudIHQ5HwuFNyHev9gnL3B8bcnK7wwO3u+SefoHbBGj/4NfBGw1rKk1KOC2I0KYpJcDUv1gJbQpY0faqM9URbrDJ4XA44sBMRCx5WqTJU1KHw7FXUYJi2qpCUgNJ30uaJmmmpD/76Z0kfScpV9Jbkur56fX9z7n+8Y5VXcM5UofDkXB4g01pMW0xsI2d0eV6AKdI6gv8HS/KXGdgPXC5n/9yYL2f/oSfr1KcI3U4HAlH6WBTLFuVtjxKgx6l+5vhrYr8r58+BDjb3z+LnSst/wucIFW+ltY5UofDkZBETDFtsSAp1Q/LuRoYDfwMbDCz0gjuS4F2/n47YAmAf3wjUGkkIDfY5HA4Eo5qrmzKkTQp6vMgMxu0iz2zCNBDUhYwDDgwkIL6OEdahnhVEx8cMJZfdFjIuq0ZnPXWBbscu/Swqdx+9Dcc9dKlbCjMoFfbZTxz6qcs29QYgNHz9+Nfk6oXxCYsFVEIXpUyvX4Jj707l/R6RmqqMX5EFq8+1jbucoaldJlMdQvhKKmGVdZYKIl91H5trNGfzGyDpLF4QeGzJKX5rc59gGV+tmVAe2Cprw3XFMirzG6dO1JJVwFbzOyVui4LxK+aOGx2V16b3o2HTxizS3rrRps5qv1Slm/a9cGevKIN14w4rcblDUtFNAxVyqJt4vbzulC4JZXUNOPxYXOYOLYps6dkxlXWsJQuk6luIRwl1TCVXyvDC1oSTM+jpBZAke9EM4AT8QaQxgLnAm8ClwAf+KcM9z9/4x//3KqIN1rnfaRm9u9EcaIQv2ri5BVt2bit/m7pdxw9gce+6YsFvH44LBXRcFQpReEWb9J+WpqRmmaBzIkPS+kymeo2LCXVsNRJq8IQRZYa0xYDbYCxkn4EJgKjzewj4A7gZkm5eH2gL/r5XwSa++k3A3dWdYFab5GWoxj6M36wZklfAN8BA4As4HIzGy8pFe8X5BQ8mZbnzexpSScAj/rfYyJwtZkFpgESlGri8R0XsLogkzl5Obsd69F6Je+d9zZrChryyNdHkbs+O65rBUVYqpQpKcYzn8ymbcdtfDikBXN+iK81WpbaVLqsKWHUbVhKqrWhTloeZgQ2Id/MfgR2W85oZvOB3uWkFwK/rs41arVFWoFiaFnSzKw3cBNwn592BdAR6FGqGCqpATAYON/MDsVzpldXcN0dKqJFxOZng1JNbJBWxBVHTOHp73vtdmzWmhYMfOV3/Ort83ht+qE8feqnNb5OslBSIq45+SAu7NWNrj0K6NB1a9UnxUgyqXIGTdhKqrVPbJPxY5mQXxvU9qt9eYqhZXnP/zsZz3mCpyr6n9KpCv55XYEFZjbXzzMEOK68i0ariKaz+2t3WYJUTWzfJJ92jfMZdt47jL5oKK0abebdX/+XnIwtFBTVY0uxp/Q4bnEH0lJKyGoQnGOJhzBVKQEK8tOY9nVjevWvWCerOtSF0mVNCaNuw1JSDfs5qAjDa5HGsiUCiVGKXSltMkaok8GwYFUT561rzrGDL+PEoRdx4tCLWLW5Eee8cy5rtzYkJ2ML3iMDh7ZcRYqMDYXhduLHShiqlE2zi8hs4k3bq9eghJ7H5rMkN4jvW1dKlzUjjLoNS0k1PHXSqomQEtOWCNS2oypPMTQWRgNXShprZsX+eXOAjpI6m1ku8Dvgy3gLGK9q4iMnjqZ32+VkNSjk84tf4ZmJvXjvp4PKzXvS/j9zQbeZFJeksK04lVtGnwjVfFUJS0U0DFXK7FZF3PrEIlJSjRTBuI+a8d2Y+P8pw1K6TKa6hXCUVMNUfq0MQ0kV2LnWVUTLUQxdyK6DTbea2SRJOcAkM+voz+X6B95gUxHeYNMzNRlsaqJs65MyMPDvteTuJAqjFxYhhdHD4p/GU75dF0YvjDB639mYuFVE23drYje/0zemvDcfPHrvUxGtQDG09Fj/qP21+H2kft/ozf4WnX8M5YzGORyOZEcuHqnD4XDEg1GtlU11jnOkDocjIXEtUofD4YgDM7kWqcPhcMSDQazLPxMC50gdDkcCklyaTXunIw1h2ktY05TmPdMncJtdrv8+cJsAKRnhzC8sKSgIxW5o07VKIoGbTGS1zzDwBptcH6nD4XDERaKsWooF50gdDkfCkWwrm5wjdTgcCUkswnaJgnOkDocj4TCDohLnSB0Oh6PGeK/2zpE6HA5HXLiVTUlOWKqJ8ahSthw6n8wZ64k0Tmfx3d0BaP3SPOqtKgQgZWsxJRlpLL7rUCguodUbC6i/uABSxJpzOrD1gOqFlAtSmfN//5ZL7wHr2JCXztWnezFmLr9jIX0GrKe4SKxY3IDH7+xMwaaaP45hKl2mpBhPj5hN3sp07r20c9z2wlInDaMOwlRSrYxkm/6U0G1nSVmSrqnNa5aqJt5zYSf+2L8rA87awL5dCgOxPeqtbO6+sGYxIvP75rD82l2luFf+vguL7zqUxXcdyuYe2Wzu0QyAphNWA7D47u4su+5AcoYtgpLqzZ0tVea8YsBB3HhmF868dG2N62H0ey245/cH75L2w4Qsrjq9B9ec2YNlCxtw/lVLa2Qbwr1nAGdfvjqgANQe8TwHFRFWHYRR1tjwXu1j2RKBxChFxWQB5TpSP0Zp4ISpmhiPKmVh5yZEGlZwrhmNpqxj0xGeuF69lVvZ0tVrgUYap1OSkea1TqtBkMqcMyY2ZdPGXcs+5assSiJei2P21MbktK75hPMw71lOm+30PiGfT17fXbiwpoShThpWHYSlpBoLTrPJR9LFkn6UNE3Sq5IGSzo36vhm/28jSWMkTZE0XdJZfpaHgf0lTZX0iKT+ksZLGg7MktRA0sv+OT9IGhBvmctTTcxpE7+0b5g0+HkTkcbpFLX0Wk3b2mWSOX0DRIy0tYXUX1JA+vqaO6qwlTlPOnc1E79sVuPzw7xnV92/lBceapfwMaCT8bmtDG/UPjWmLREI7acmSjH0KDNb68uDPF5B9kLgl2aW70fG/9Z3lncC3cysh2+zP9DTT1sg6RbAzOxQSQcCoyQd4MupRpflCjwlUhqQuDK9NaXxpDw2HblTAiO/XwvqrdrKvv+YQVF2PQo7NaKmb0BhK3NecPVSIsVi7PDgWnxB0eeEjWxYm0bu9IZ077eprouzV5FsE/LDbJHGohhaioC/SvoR+AxoB1TUU/69mS3w948Bhvr2ZwOLgAPKnlAdFdG6Uk2sMRGj0bR1bO4ZJX+VKtae04HFdx3Kiiu7krI1sqO1Wh3CVuYc+KvV9B6wjn/c0oXqalVFE9Y9O7jXZvqetJEh38zgrmcXcNjRm7j9qQVVn1gHJN1zGwNBvdpLai9prKRZkmZKutFPv1/SMv+Nd6qk06LOuUtSrqQ5kk6u6hq13UdaXHpNSSlA6bvIhUAL4Ai/9bkKqOg/P6QIFh51qZpYExrO2cj2VhkUN9v5A6HtEbTNC5zR8KeNkCK2t6luSzxcZc4jjl3Pr/+4jD9fdRDbCuNr6YZ1z15+uB0X9TqUS/p142/XdmLahMb844a6GHipmmR7bquidNQ+li0GioFbzOxgoC9wraTS0c8nzKyHv40A8I9dAByCpxP3nKRKH9Iwe5HLUwxdCBwBvA38D1D6k9kUWG1mRX4/Zwc/fRPQuJJrjMdzwp9LOgDYF09dtMaEqZoYjypl65dzyZiXT+rmYjreM4V1p+1D/lEtaTw5j81H7GojdVMx7Z6dDYLirHqsvGT/apc1SGXOO56YS/feG2nSrJhXx0/i1Sfbc/5Vy0ivV8JDg2cC3oDTM/dWv5xQd0qXNSUMddKw6iAsJdVYCGpE3sxWACv8/U2SfsJ7662Is4A3fSHNBZJygd7ANxWdEKqKaDmKoXcAHwAZwKfAtWbWyO8X/RBoBEzC+9U41cwWSnod6A58AnyMpzJ6hm+/AfAv4Ei8X52bzWxsZWVqomzroxMC/65hkVRh9BqG0//swuglF0GoiDY7sKUd/9K5VWcE3jv6X4uAtVFJg8xsUHl5JXUExgHd8MQ0LwXy8fzOLWa2XtIzwLdmNtQ/50XgEzP7b0VlCHVeQwWKodEaq3f4+dYC5eoZm9lvyyR9EXWsELgs7oI6HI6EoxqDTWtjkWOW1Ah4F7jJH9j+F/AAXk/CA8BjwO9rUla3ssnhcCQcQa9skpSO50RfM7P3AMxsVdTx54GP/I/LgPZRp+/jp1VIok/IdzgceylBDTZJEvAi8JOZPR6V3iYq2y+BGf7+cOACSfUldQK6AJX2h7kWqcPhSDgCnkd6NPA7YLqkqX7a/wG/kdQDrwG8ELgSwMxmSnobmIU39nKtmVXa8e0cqcPhSEiCWv5pZl9R/kTlEZWc8xDwUKzX2DsdaQijtUoJZxVGGCPs8/4Z/EwAgC43fhuKXaWF85haJIlG1/eyGQZmUOwCOzscDkd8JNMSUedIHQ5HwpFsa+2dI3U4HAmJOUfqcDgc8ZEosUZjwTlSh8ORcJi5PlKHw+GIExFxo/bJT9CCZwBDJkxnS0EKJRERiYgbzjgobpvxitS1fP1nMmeuJ9IoncV3HQZA68Fzqbe6jKje7d1Jyyukw9+mUdQyA4DCDo1Yff5+1SpvWGJqiVi3FRFGHaTXL+Gxd+eSXs9ITTXGj8ji1cfaBmI7TGHBynB9pAEi6X5gs5k9WpvXLRU8a9go2Hl2d5zflfwANXBKRepyZzQkIzPCM5/OZcq4xiyeF1sItfzeLdh4bGtaDc3dkbby0p2xsXOGLaIkY+ccxqLmDVh8e/cal3fUW9kMfzmH255cUmMbFZFodVsRYdRB0TZx+3ldKNySSmqa8fiwOUwc25TZUzLjslsqqnfXBfuxdkU6T4+Yx7cjm8ZdB1XhVET3AMIQPAuLeEXqPFG9CiZ7m9Foah6begYXf7IuxdSqS5ACgNGEUweicIt3H9PSjNQ0C0RnKkxhwUoxr580li0RSEhHKuluSXMlfQV09dN6SPrWF9MbJqmZn36DLyHwo6Q3g7h+WIJnZvDXoXN5+uOfOPW3a4I1TvAidTtF9TJ2pKWv20b7f/xIu6dm0uDn/ECuEwTJVrdhkJJiPDfyJ96a9iM/jG/CnB/ia41C3YrqJZOKaMI1DSQdgRfmvwde+aYAk4FXgOvN7EtJfwHuA27CE8jrZGbbJGVVYDNm8bswBc9uOacreavq0bR5EX97bR5Lchsw4/vKBABiJwyRusZT1u7SGo00rceC+w+nJDOd+ks20+aFuSy+qzslDer+MUq2ug2DkhJxzckHkdmkmPtemE+HrltZNCej6hMTEEuywaZELOmxwDAz22Jm+XghrTKBLDP70s8zBDjO3/8ReE3SRXiRWnajOuJ3YQqe5a3yftk35qXz9cgsuvYIJvJ7KCJ1EaPRtPVsjnKklpZCSaanDrOtfSOKcuqTvrqwIgu1SlLVbcgU5Kcx7evG9Oof/xtDXYrquVf72uV04Fk8meaJkuJqHoUleFY/I0JGZmTHfs9j81kYSGshHJG6hnM3sr1VA4qzdv7wpG4ughLvyU1bW0i9NYUUNa97baRkq9swaJpdRGYTrx1Rr0EJPY/NZ0lu/PemLkX1zBTTlgjU/TvZ7owDBkv6G175zgT+A6yXdKyZjceLLfilr0Ta3szG+v2pF+DpPm2om6JXTLMWxdw76GfAa+WMfT+byV/G/0DGK1LXesg8MnJ9Ub17p7Du1H3I79eSxlPWsrnnroNtGbn5ZH+yFFKFCVaftx8lmdV7hMIQU0vUuq2IMOogu1URtz6xiJRUI0Uw7qNmfDcm/jqoK2FBr7WZGE4yFkIVv6spku4GLgFWA4vx+kk/A/4NNATm42k1bQbG4qmQChhqZg9XZruJsq1P6knBlzmkMHphhHpzYfQ8QgujF8b/VBKF0QtC/C6jc1vb77ErYso76+w/T45FsylMErFFWllQ1b7lpB0TcnEcDkcdkIBtvApJSEfqcDj2bgxRkkSj9s6ROhyOhCSJGqTOkTocjgQkyQabnCN1OByJSRI1SZ0jdTgcCcke0SKV9DSV/CaY2Q2hlKg2CGHKh5UEbtIjhGkvYU1T+vmx8iZVxM/+t4RT3tAIY6pSgqp9hoXhLXlNFiprkU6qtVI4HA5HNAYE1CKV1B4vVkcr3/IgM3tSUjbwFtARWAicZ2brJQl4EjgN2AJcamZTKrtGhY7UzIaUKUxDM9tS86/jcDgcsRPgPNJi4BYzmyKpMTBZ0mjgUmCMmT0s6U68AEh3AKcCXfytD/Av/2+FVDlRS1I/SbOA2f7nwyQ9V/Pv5HA4HDFgMW5VmTFbUdqiNLNNwE9AO+AsvABI+H/P9vfPAl4xj2+BLEltKrtGLDNe/wmcDOT5BZnGzshLDofDEQKxBSzxB6RyJE2K2ipcWyqpI3A48B3QysxW+IdW4r36g+dko+ULlvppFRLTqL2ZLfG6DXawd/V8OxyO2if2V/u1say1l9QIeBe4yczyo32amZmkGncmxOJIl0g6CjBJ6cCNeE1jh8PhCAcDC3DU3vdd7wKvmdl7fvIqSW3MbIX/6r7aT18GtI86fR8/rUJicaRX4Y1gtQOWAyOBa2P/CslHWKqJYdhNRPXIv/X5guPbLiKvMIPTPjkPgCePGk2nJp7WT5P0beQX1ed/Pj0XgKsO/oFf7zebiIkHJh/N+JXtK7RdHmEpk0Jy3bNkem5jI7BRewEvAj+Z2eNRh4bjRZl72P/7QVT6db50UR9gY1QXQLlU6UjNbC1wYfWLn5yEpZoYlt1EVI98b/4BDJ17CI/0Hbsj7cavT9yxf9fh37BpuxfRvnOT9Zy+by6njjiPlhkFvDLgYwZ+fD4lFnvAirCUSZPpniXbcxsTwY3aH40Xw3i6pKl+2v/hOdC3JV0OLALO84+NwJv6lIs3/emyqi4Qy6j9fpI+lLRG0mpJH0iqnph5EhGWamJ4aoyJpx45cU1bNmyv6B/NOK39z3y4qDMAA/dZyMeLO7O9JJWlBU1YtLkJh2WvruDc8glLmTSZ7lnyPbcxENyo/VdmJjPrbmY9/G2EmeWZ2Qlm1sXMBprZOj+/mdm1Zra/mR1qZlXOqY/lZ/914G2gDdAWeAd4I4bzkNRR0k+Snpc0U9IoSRmSvpB0pJ8nR9JCfz9V0iOSJvqqoFf66W9KOj3K7mBJ51aUPx7CUk0MU40xmdQje7VYwdrCDBZt9qK3t8ooYMWWneVduSWTVg0TY7pyMt2zZHxuK6V0Qn4sWwIQiyNtaGavmlmxvw0FqtOu7wI8a2aH4EmAnFNJ3svx+iN6Ab2AP0rqhLf64DwASfWAE4CPK8m/C5KuKJ0aUcS2ahQ9OShVj7ywVze69iigQ9etdV2kCjmjw898tLhzXRejzkmme1ZX7BHid5Ky/SVUn0i6029ddpB0O14fQqwsMLOp/v5kvOVYFXEScLHfj/Ed0BzPEX8CDJBUH2/VwTgz21pJ/l2ojopoWKqJtaHGmOjqkakq4eT2C/h40f470lZtzaRNw52Kn60bFrBqS2JoxyfTPUvm57ZCShTblgBU1iKdjLfe/jzgSjxtpC+Aq4Hzq3GN6CZgBG+Aqzjq2tGtW+Fp15f2Y3Qys1FmVuhf+2T/2m9Vlr8aZduNsFQTw7KbTOqRR7deyvz8LFZubbQjbczSDpy+by71UiLsk5lPh8YbmbYuMRQ7k+meJdtzGwuy2LZEoLK19vFrEFfMQuAI4Hvg3Kj0kcDVkj43syJJBwDLzKwAz3n+ATgSb41sVflrRFiqiWHZTUT1yCeO+ow+LVfQrH4hX501lCenH8k78w/k9H13DjKVMi8/mxGL9+fT096m2MT9k46p1og9hKPKCcl1z5Ltua2SGAeSEoWYVEQldQMOJqr1aGavxHBeR+AjM+vmf74VTy75TbwBrAheX+dFZtbRl1d+EE+CWcAa4Gwz2+hPqF0FfGBml/n2KsxfUZmaKNv66IQqv3PCkEQh2VwYPZ8kumdhEISKaP0O7a3N/90YU95FV92W+Cqiku4D+uM50hF4fZRf4YWlqhQzWwh0i/r8aNTh7lH79/jHS/Dmd/1fObaKgOwyaRXmdzgcSU4StUhjeYc6F2+UfKXfEjwMT0fe4XA4wqMkxi0BiGUW81YzK5FULKkJ3nrU6q3hczgcjuoQYGDn2iAWRzpJUhbwPN5I/mbgmzAL5XA4HIkyIh8Lsay1v8bf/bekT4EmZvZjuMVyOBx7PXuCI5XUs7JjVWmYOBwOx95CZS3Sxyo5ZsDxAZel9ghjekpYMqKhyZMGT+c7w/ltXXzPUaHYbf/g16HYDWOqktLCUU63SAjTqgJqSe4Rr/ZmNqA2C+JwOBw7MBJm+WcshPMz53A4HPGyJ7RIHQ6Hoy7ZI17tHQ6Ho05JIkcaS4R8SbpI0r3+530l9Q6/aA6HY68moAj5tUEsS0SfA/oBv/E/bwKeDa1EDodjryfWEHqJ8vofy6t9HzPrKekHADNb70ep3yMJS+GxRdvt3PbkYrJyisDEiNea8/6LLRLWbljKnJlNirnp7wvpeMBWDHjitk78NKVRlecBPDhgLL/osJB1WzM4660Ldjl26WFTuf3obzjqpUvZUJhBr7bLeObUT1m2qTEAo+fvx78mVT9AUDIpcw6ZMJ0tBSmUREQkIm4446C4bYb1fMXEHjZqXyQpFb8RLakFtRwqQNJgvHB8/w37WmGpckaKxaA/tyV3RkMyMiM88+lcpoxrHLcaY1h2w1LmvOq+xUz+sikPXd2ZtPQS6mfE/igNm92V16Z34+ETxuyS3rrRZo5qv5Tlm3Z1yJNXtOGaEafVuKzJqMx5x/ldyQ9QCDCs5ysWEqW1GQuxvNo/BQwDWkp6CC+E3l9DLVWdEo4q57rV6eTO8CQ0thaksmRefXJaxy8iFpbdMJQ5GzYu5tA+m/j0zRwAiotSKMiP/RqTV7Rl47bdpWLuOHoCj33TFws4yMUeqcxZTcJ6vmJiT+ojNbPXgNuBvwEr8AInvxPExSXdLGmGv93kp13sK4JOk/RqVPbjJH0tab6kc/288lVEZ0iaLqk6EigVEoYqZzSt9tnG/t22MvuHYLWJwrIbFK3bb2djXjq3PLqAZ0bM5Ka/L6B+Rnwra47vuIDVBZnMycvZ7ViP1it577y3+c/pH9G52bpq2042ZU4z+OvQuTz98U+c+ts1cdsrS60+X0nWRxrLqP2+wBbgQ2A4UOCnxYWkI4DLgD5AXzwF0KPxgjwfb2aHAdEhstsAxwBnAA/7ab8CeuDFSB0IPCKpTTnXqpaKaJgKjw0aRvjT8wv5933t2LI5uKWqYdkNktRUo3O3Aj4a2pLrTjuEwi0pnH/Nihrba5BWxBVHTOHp73vtdmzWmhYMfOV3/Ort83ht+qE8feqn8RQ9KbjlnK5cd/rB3HNxZ868eA3dem8KzHadPF8BtUglvSRptaQZUWn3S1omaaq/nRZ17C5JuZLmSDo5lqLG8mr/MfCR/3cMMB9P1TNejgGGmVmBmW0G3sPTY3rHzNYCmFl0M+J9Mysxs1lAqygbb5hZxMxWAV/iyTLvQnVURKMJUpUTIDXN+NPzC/l8WDMmfJIViM0w7QbN2pX1WLuiHnOmen2Z40dk07lbzTXs2zfJp13jfIad9w6jLxpKq0abeffX/yUnYwsFRfXYUuypXY5b3IG0lBKyGlTvBzHZlDnzVnmt3I156Xw9MouuPWosXbYLdfV8qSS2LQYGA6eUk/5ElHDmCABJBwMXAIf45zznjxFVSiyv9oeaWXf/bxegN3UTjzS6KRnacF5Yqpxg3PzYYpbk1ue9QUGqZIZlN3jWr0lnzYp67LOf59AOPzqfxfMyamxv3rrmHDv4Mk4cehEnDr2IVZsbcc4757J2a0NyMrZQ2lw5tOUqUmRsKKzefUwmZc76GREyMiM79nsem8/COTWv250kz/NVEWY2Doi1b+cs4E0z22ZmC4BcPJ9XKdUeTTCzKZL6VPe8chgPDJb0MJ5j/CWe7PPLkh43szxJ2WVapeXZuFLSEDw9p+OA2+IpVFiqnIf0KmDgueuZP6sBz42aDcDLD7dl4udNEtJuWMqcz93XgdufnE96urFicX0evzV2sdpHThxN77bLyWpQyOcXv8IzE3vx3k/lT/E5af+fuaDbTIpLUthWnMoto0+kur+/yaTM2axFMfcO+hnwWpBj389m8peJ+9zGROz9nzmSJkV9HmRmg2I47zpJF+PJzt9iZuuBdkC02uJSP61SqlQRlXRz1McUoCfQ3Mxi6juIwfbv/Y8vmNk/JV2C5wwjwA9mdmnZ6U+SNptZI0kC/oEnyGfAg2b21m4XiqKJsq1P6knxFn13kijcXSDTEMpB6eFML158RzgCkaGF0QuBZAqj913JZ3GriDZo2946Xnlz1RmBOfffXKWKaDmKxq2AtXh+4wGgjZn9XtIzwLdmNtTP9yLwSVVTL2O5O42j9ovx+krfjeG8KjGzx4HHy6QNAYaUSbu0zOdG/l/Dc7pxtUIdDkcCEuKIvD+mAoCk5/HGgQCWsasm3T5+WqVU6kj9TtbGZnZr9YvqcDgccRCiI5XUxsxKp4z8Eigd0R8OvC7pcaAt0AX4vip7lUmNpJlZsT8lyeFwOGoNEfOIfNW2pDeA/nh9qUuB+4D+knrgueuFeOMzmNlMSW8Ds/DewK81syr7PyprkX6P1x86VdJw4B1gx3wKM3uv+l/J4XA4YiDAyfZm9ptykl+sJP9DwEPVuUYsfaQNgDw8jSbD+7EwvHmfDofDEQ4JsmopFipzpC39UfUZ7HSgpSTRV3Q4HElJEnmZyhxpKtCI8iffJdFXLIOE0oOfSmLbql56WiOUPKHErGh71ZlqQFjTlBY+1C8Uux3vDn69ihUXB24z0UmUdfSxUJlHWWFmf6m1kjgcDkc0e4gjTZ6mkMPh2LOw4Ebta4PKHOkJtVYKh8PhKMue0CKtYo27w+FwhMqe0kfqcDgcdYdzpA6HwxEHCSQjEgvOkZbDL3+/klPOX4MZLJyTwWO37UfR9lhiYFdOGMqcyaYimoiqnH89eiz92y8irzCDM9/31Gqu6zGR8w74iXWFXkzPx6f0ZtzSDpy531wu7zZtx7lds/P45fBzmb1ud6mTsMpbmzbDeg6qQiTXq3383qEOkPQXSQPDsN281XbOunQl1//PIVx1yqGkpEL/M/MCsT3qrWzuvjD2+JuxUKryeMWAg7jxzC6ceela9u1SGLfdMMpaqp55z4Wd+GP/rgw4a0MgZY3X7nu5XfnD6NN3Sx88qztnD/81Zw//NeOWdgDgw/kH7Ei7ffzxLN3UpNpONIx6CKtuw3gOYmWP0mxKRMzsXjP7LCz7qaledPyUVKN+gwh5q4OJsxmGMmcyqYgmqirnpFXlq5NWxemdcvl4wf7VPi+MegirbsN4DmJmT1IRrS0kZUr62FcPnSHpfElHSPpS0mRJI0uF7SQNjlISfVjSLF959NF4y5G3qh7/fb41r06Yyuvf/UDBpjSmjI8/0nhtkOgqosmmynnhgTMYftbb/PXosTSpt/vKtdM6/czH87tU224Y5Q2rDuoU50hrxCnAcjM7zI9i/SnwNHCumR0BvESZiCySmuPFEjzEzLoDD5ZneBcVUav8dadRk2L6nbieS487jAv79qBBwwjHn702/m8XMsmgIppMvDH7EE5897ec9cGvWb21IXf22nWZavecVWyNpDFvQ3YdlXAPZ0+TY65FpgMnSvq7pGPxolR3A0ZLmoon07xPmXM2AoXAi5J+hScbvRu7qIiqcm2cw4/JZ9WS+mxcl06kOIUJI7M5qOfm+L5ZyCSLimgyqXLmFTakxFIwxDtzD+LQFqt3OX76frl8PL9z4pQ3pLqtU1yLtPqY2Vy8+KfT8VqW5wAzo+RSDzWzk8qcU4yn8PdfPL37uMXLVy+vx4GHF1C/QQQwehy1kSU/B6EiGhbJo/KYTKqcLTJ2ShkP3HcB89bvbHkK49SOP9fYkYZR3rDqti4JUI45dBJm+pOktsA6MxsqaQNwDdBCUj8z+0ZSOnCAmc2MOqcR0NDMRkiaAMyPtxxzpjZi/CfNeOajmUSKxc+zGvLJG8E4qDCUOZNJRTRRVTkf+8Vn9G69nGYNCvnyvFd5+ocj6d16OQc2zwODZZsbc+/Xx+3I36v1clYUNGLp5prVcRj1EFbdhqUmGwuJ8toeC1WqiNYWkk4GHgFKgCLgarxQ/08BTfGc/j/N7PlSVVFgAvABXvBpAY/64nkV0iSlufWtf2rg5U+qMHoJcs/rmmQKo5dMfGdj4lYRbdiivR14Tmwqoj/8p2oV0bBJmBapmY0ERpZz6Lhy8l4a9bF3WGVyOBx1SBL93ieMI3U4HI5Skm1lk3OkDocjIVFJ8nhS50gdDkfikUBTm2IhYaY/ORwORzRBTciX9JKk1ZJmRKVlSxotaZ7/t5mfLklPScr1V0v2jKWszpE6HI7EJLgJ+YPxVk5Gcycwxsy6AGP8zwCnAl387QrgX7FcYO97tTcLb6pSGCiE3zqLBG8TUP3qB/6IhbDuV1jTlFbcfFTgNtv887vAbQJQEs6zEARBDTaZ2ThJHcsknwX09/eHAF8Ad/jpr5g3L/RbSVmS2pjZisqu4VqkDocjMYm9RZpTGkvD366IwXqrKOe4EigN3toOWBKVb6mfVil7X4vU4XAkPtVTEV0bz4R8MzMpvvava5E6HI6Eo3QeaYjRn1ZFheVsA5RGpVmGFzCplH38tEpxjtThcCQmZrFtNWM4cIm/fwneUvPS9Iv90fu+wMaq+kfBvdo7HI4EJajBJklv4A0s5UhaCtwHPAy8LelyYBFwnp99BHAakIsXlvOyWK7hHGk5JKJAW1WkpBhPj5hN3sp07r20ZuHdoglD9Gyf/bZy19M/7/jcun0hrz6xD++/3Douu2EKtMVzz/588lh+sf9C1m3J4FeDLwDg2qO/Z0DnBZSYWLclgz99cjxrCjLpmL2eB04Zy0Et1/D0V30YMqlHtcqZXr+Ex96dS3o9IzXVGD8ii1cfa1stGxUR5nNbIQFOyDez31Rw6IRy8hpwbXWvkTCv9pJekHRwFXlukhSqjkaiCrRVxdmXr2ZJbnBxU8MQPVs6P4NrT+/Gtad34/ozD2FbYSpfj2oWt92wBNrivWfDZ3bl6v+esUva4Ik9OHfI+Zz3ynmM+7kDV/abBEB+YX0e/vyYajvQUoq2idvP68LVJx3E1ScfxJH98zmwZ0HVJ1ZB2M9tZSRTPNKEcaRm9gczm1VFtpuAUB1pogq0VUZOm+30PiGfT16vnpplZYQtetbj6HxWLKrP6mXxzz0Nq6zx3rPJS9uysXDX71ewfaeuUkZ68Y79dVsaMnNlS4pLavovKQq3eBIzaWlGapoFEi0xzOe2KpwjrYIKhO6+kHSkf/wkSd9ImiLpHUmNJN0AtAXGShpbUb54y5ZsAm0AV92/lBceapdUYUZ/cUYeX3xYOwGCa0pY9+z6Y75j1BWvcPrBc3l2QnBRIFNSjOdG/sRb037kh/FNmPNDZtw260xUzwh7sClQ6qpFWp7QHQCScvD0mQaaWU9gEnCzmT0FLAcGmNmAivKVd7FdxO9IolVNMdDnhI1sWJtG7vTEVA4tj7T0EvoO3MD4EXuncNzTX/XhpEEX8/GsA/jN4dMDs1tSIq45+SAu7NWNrj0K6NB1a2C26wInflc1uwjdmVn0u0Jf4GBggi96dwnQoRwbsebbVfyOyl8lk0mgDeDgXpvpe9JGhnwzg7ueXcBhR2/i9qcWxG03TI7sv5HcmQ3ZsDaxxdnCFpT7+KcuDDwgbnWc3SjIT2Pa143p1T8/blt1KqrnxO8qp6zQnaR7ow4LGB0lenewmV1ejplY81WLZBJoA3j54XZc1OtQLunXjb9d24lpExrzjxuCH3gJkv5n5vHF8MR+rYdw7tm+WRt27A/ovJAF6+IfbANoml1EZhOvz7VegxJ6HpsfyOBjXYnq1cKE/ECpk+lP5Qjd/SHq8LfAs5I6m1mupEygne98NwGNgbVV5KsxiSrQVtuEJXpWPyNCz2M28tTdHeMvpE9YZY33nv399NEc2X45WRmFjL7yFZ6b0Itj91tEx+wNlJhYkd+YB0Z7SjrNG27hzd/9l8x62ykxcdERP3L2yxfsMjhVGdmtirj1iUWkpBopgnEfNeO7MfE7vDp7bs2SKrBznYjfVSB09yhwq5lNknQ88HfY8R5+j5kNl3Q9cB1e/+qAivJVdu0myrY+2m36WOKSkhq8zZAi/iRb9Kew2NujPwUhftc4ax87/LgbY8o7/sPb907xuwqE7vpHHf8c6FXOeU8DT1eVz+FwJD+J8toeC25lk8PhSDwMSKJXe+dIHQ5HYpI8ftQ5UofDkZi4V3uHw+GIk2QatXeO1OFwJB4JNNk+FvZORxrClKLUpk0CtwkQWb8+eKOKa2ZKhdj27VVnqgHJNq2qzeNfB25z+W3BT6kCaPtI8GUNAm9CfvJ40r3TkTocjsQnQSI7xYJzpA6HIyFxLVKHw+GIB9dH6nA4HPGSXGvtnSN1OByJiXu1dzgcjjiwxJERiQXnSMsQpBrjTQ/Mpvcv8tiwLp1rzvYkJe58dCbtOm0BoFHjYjZvSuP6c+KLuxKGymOLttu57cnFZOUUgYkRrzXn/RdbJJxNCE+dFBJPUfYvJ47luP18ZdJXPWXS6/p9z4D9fWXSrRncM9JTJi3lkFarGXrBe9w+4kRGz9u/WuUMU6G1SlyLtPpIygJ+a2bP1WU5StUYC7ekkppmPD5sDhPHNmX2lOrr33z2fms+fL0dt/ztpx1pD996yI79P9yWS8Hm+G5BqcrjXRfsx9oV6Tw9Yh7fjmzK4nnxxYyMFItBf25L7oyGZGRGeObTuUwZ1zguu2HYhJ3qpODVx9BvpwaiThpW3cZj94NZXXljWjceOnnMjrSXJ/fgmW+8H+rf9viRq/pO4oExv/CupRL+95hv+GZR+xqVddRb2Qx/OYfbnlxSo/PjInn8aOKoiAJZwDVlEyXVsrMPTo1xxuQsNm2sqPjGsSev4cuPW9bMuE9YKo/rVqeTO8PTgdpakMqSefXJaR2f6FkYNssSpDppIirKTl5WtTJp9PP62x7T+Sx3f9ZtyahRWcNWk60MlZTEtMVkS1ooabqkqZIm+WnZkkZLmuf/rfGvbyI50oeB/f0vOlHSeEnDgVmSUiU94qf/KOlKAEltJI3zz5kh6dggChKGGmNZuh2xkQ156SxfHJ9oXW2oPLbaZxv7d9vK7B+CE9gLwyYEq06aTIqy1x/1HaP/8AqnHziXZ/3WacvMzZzQeQFvTTukirMTEMObkB/LFjsDfFmi0iDQdwJjzKwLMMb/XCMSyZHeCfxsZj2A2/A0nW40swOAy4GNZtYLL5DzHyV1An4LjPTPOQyYWp7h6qqI1oYa4y9OW80XI4LpbwuTBg0j/On5hfz7vnZs2RzM0towbMLerU769Nd9OPGFi/l49gH8poenTHpH/wk8Mb4vRjhLgsNEGLLYtjg4Cxji7w8Bzq6poYTpIy2H782sVA7zJKC7pHP9z02BLsBE4CVJ6cD7Zja1PENmNggYBJ7USKwFiFZjXDSnZq9G5ZGSWsJRA9dww3lHxG0rTJXH1DTjT88v5PNhzZjwSVbC2iwlaHXSZFOUBfh4dheeO/tjnvumNwe3WsM/TvsMgGYZWzmm0yIiJSl8/nNiiyPuIHYnmVP6uu4zyP+f38UaMEqSAf/xj7cysxX+8ZVAjVs2iexIC6L2BVzvS5TsgqTjgNOBwZIeN7NX4rlo0+wiiotFQX7aDjXGt5+Lf/Q3msP7rWfpgobkrQpW5TFvZTr9z9rAw9eWq0pdTYybH1vMktz6vDcovn7ccG3uJGh10rDqNmi7+2ZtYPGGLACO338hC9Z7XX2nvnTRjjwPnvQ5Xy7okDxOFKrjSNfGoNl0jJktk9QSGC1p9q6XMvOdbI1IJEdaqhBaHiOBqyV9bmZFkg4AlgE5wFIze15SfbzugLgcaZBqjLc/MovuvTbQJKuIV8Z8zdBnOzHqvTYcd+pqvhwRjCMJS+XxkF4FDDx3PfNnNeC5Ud4z9/LDbZn4ec2jXIVhs5Qw1EkTUVH276eOplf75WQ1KOSzP7zCs9/04thOi+jYbANmYvmmxjzw2XFxl7GUsBRaq6S0jzQoc2bL/L+rJQ0DegOrJLUxsxWS2gCra2q/TlREK0LS60B3YCuwyszO8NNTgAeBM/Fap2vw+jPOxutPLQI2AxdHdQeUSxNlW5/UkwIvuwujFx6qF5skcXVJJnXSZAqjF4SKaNOGba1fl8tjyjvyxwcrVRH1pdpTzGyTvz8a+AtwApBnZg9LuhPINrPba1LeRGqRYma/rSC9BPg/f4tmCDs7ix0Oxx6DBTkhvxUwTF4DIg143cw+lTQReFvS5cAi4LyaXiChHKnD4XAAfvSnYBypmc3Hm9VTNj0Pr1UaN86ROhyOxMSttXc4HI74cIGdHQ6HI16cI3U4HI44MINI8rzb752OtCQSuMlQpilBKIqnYXz/UImEVN4w6hbAgncAYal9ZnwZ/DLllD8G5FZci9ThcDjixDlSh8PhiAMDnGaTw+FwxIOF0kUSFs6ROhyOxMNwg00Oh8MRN66P1OFwOOLEOdLkJizlxDDsBql6Gk1YdRCWKueQCdPZUpBCSUREIuKGMw6K22ZYdRuWmmo896xkdYSihzZi60tAkHZmQ9LO3SkDU/RWAcXPbabBBy1QVgpFbxQQ+azQOxgxbFHEO9YkKNGNQIOWhI5zpOUQlnJiGHaDVD2NJoyyhqXKWcod53clP0ChtrDqNiw11XjumVIh/drGpByQjm0pYdsf15FyZD1SOqZRsjpCycTtqNVOJ5n+m0zSf+PVQ2TCNorfKQjQieKP2idPH2kiaTYlDGEpJ4ZjNzjV02jCKGtYqpzhEU7dhqWmGs89U/NUUg7w5E7UMAV1SMPWeAship7ZRPpVjahI+ikyppDUE4L5MdwFs9i2BCChWqSSOgIfmVk3//OtQCOgP/AdMABPtvlyMxsvqQHwL+BIoBi42czG1n7J65aUFOOZT2bTtuM2PhzSIhTV0yAoTz3zwJ5bArFtBn8dOhdDjHgth09ej/9VGcKv27DUVOOhZEUEm1dEysFNiHxViHJSSOlcvqaUFRqR77eRflNF4hY1xS0RDYs0M+st6TTgPmAgcC2e3Mqhkg7EE7c6wMwKo0+UdAVwBUADEueBDYpS1dPMJsXc98J8OnTdGqhYXzJwyzldyVtVj6bNi/jba/NYktuAGd/H/88dZt2GpaYaD7alhO33biD9+saQKoqGFlD/0Yrl3iNfbyOlW3qwr/Xgd5EmjyNNplf79/y/k4GO/v4xwFAAM5uNF+X6gLInmtkgMzvSzI5Mp34tFLVuiFY9TUTCVM/MW+W1dDfmpfP1yCy69iio4ozqEXTdhqmmWlOs2Nh+70ZSBzYg9bgG2LJibEWEbZfnUXj+GmxNCdv+mIfl7Yx9ENprPXgrm2LZEoBEc6TF7Fqm6DtUKrATIbla0qHSNLuIzCbFADtUT5fkhvRgx0m0emZaegn9z9rAt6NqJiwYTf2MCBmZkR37PY/NZ2EArcbw6jZcNdWaYGYU/T0fdUgj/Xyv+yJl/3QyPmhJg7da0OCtFqhFCvWfb46ae61n21xCybTtpB4T0vPm+khrzCqgpaTmeGJ2ZwCfVpJ/PHAh8LmvLLovMCfeQoSlnBiG3SBVT8Mua1iqnM1aFHPvoJ8Br6U39v1sJn8Zfx2EVbdhqanGc89KphcRGVWI9kuj8PI8ANL/2IjUvhW/wUXGbyO1Vz2UEYKYollSjdonlIoogKQbgBvx5JbnAwvxBptuNbNJknKASWbWsSaDTU2UbX0UiExL7eDC6KG0cH7vLazXwjD69kL6Pw0jjN64P77Nhtmr41MRTc2xfplnxpR35KbBlaqI1gaJ1iLFzJ4Cnqrk+Fr8PlJ/UOmy2imZw+GoPQwLKw5tCCScI3U4HA4XRs/hcDiCwE1/cjgcjppjeH3YsWyxIOkUSXMk5Uq6M+jyOkfqcDgSD/MDO8eyVYGkVOBZ4FTgYOA3kg4Osrju1d7hcCQkAQ429QZyzWw+gKQ3gbOAWUFdIOGmP4WNpDV4K6BiIQdYG0IxwrCbTGVNNrvJVNZEsNvBzOIKdiDpU/96sdAAiF4WPsjMBkXZOhc4xcz+4H/+HdDHzK6Lp4zR7HUt0urcYEmTwpifFobdZCprstlNprImo93yMLNTauM6QeH6SB0Ox57OMqB91Od9/LTAcI7U4XDs6UwEukjqJKkecAEwPMgL7HWv9tVkUNVZEsZuMpU12ewmU1mT0W6omFmxpOuAkUAq8JKZzQzyGnvdYJPD4XAEjXu1dzgcjjhxjtThcDjixDnSEJB0laSL6+jaWZKuieP8+32trKRD0mB/zmBY9v8iaWA1z3mhqlU0km6SVKUGTrz31hEezpFWA0kxDc6Z2b/N7JWwy1MBWUC5/2yxlt9RPmZ2r5l9Vs1z/mBmVa2guQliEhPLopx76+5r3bPXOlJJF0v6UdI0Sa9KaiHpXUkT/e1oP9/9/vEJwKuSOkr63D93jKR9y7G1o1Un6QtJf5f0vaS5ko7101MlPSpphn/u9X76w5K2+luupFeiW1mSNvt/G/nXnyJpuqSz/CwPA/tLmirpEUn9JY2XNByYJamBpJf9c36QNEDS3X7ZvgK6+vZ7SPrWL9swSc389BskzfLTP5T0k6TnJc2UNEpShv+dj/Tz50haGPWdH/Hr90dJV/rpb0o6Peo7DpZ0blT+xZIKJS2TdFN59y/q1h4n6WtJ80vrTR6P+HU9XdL5UdfKlPSxb2eGpPMlHSHpS0mTJY2U1Ca6XFH3qbQeHq3EVnRdnCTpG/+evePfwxuAtsBYSWMrylfOvZ1Y5r5WVLdtJI3zz5kh//kr5/+ho6QZUZ9vlfccV/T87vYclfuPtrdgZnvdBhwCzAVy/M/ZwOvAMf7nfYGf/P378QT3MvzPHwKX+Pu/B8aUY+t+vIj+AF8Aj/n7pwGf+ftXA//FU0ctPe9woAhv+RrAm8D3wLlRZd/s/00Dmvj7OUAunvJ4R2BGVP7+QAHQyf98C970D4ADgRXADLwWURPfzq3Aj8Av/Hx/Af7p7y8H6vv73fGUCXr4n98GLvK/85FRZVvo718B3OPv1wcmAZ2AXwJD/PR6wBIgw8//HDAdaAZM8ev66LJ17v8dDLyD10A4GG99NcA5wGi8qS+tgMVAm6hjz0fVV1Pga6CF//n8qPoaDJwLNMeTtCmd9ZJVia0v8BQccoBxQKZ/7A7gXn9/YdR3qSzfjntbzn2tqG5vAe7201OBxhX8T+yw7X++Fe85/oLyn9+yz9FioEFd/2/X1ba3vhIcD7xjXrR9zGydvL6vg6UdCglNoloCw81sq7/fD/iVv/8qXjT/J8vYKnu98hRQBwL/NrPiqPNuA1aY2Xd+nueBlyr4DgL+Kuk4oARoh+ckyuN7M1vg7x8DPO1fc7akLcBXZrYFwG/hZOI5hy/9c4bgOSjwHOxrkt7Hc2wLzGxqOd+vPE4CumtnC7sp0AX4BHhSUn3gFGCcmW2VdBJQ+v3GstPJHUmZ+xd1jffN0/GdJam0Po4B3jCzCLBK0pdAL7xJ2dOBxyT9HfgIWA90A0b79zEV78cmmo14a7tflPSRfx5lbZnZ+KhnoS+ec5/gp9UDvimnjmLNB7ve14rqdiLwkqR0v26mVmCrMipS8I1+jkoVfH+sgf2kZ291pOWRAvQ1T75kB/7DHK+2bzwKqCV+2ZCUgvePBZ7oXwvgCDMr8l+fK1KSC1Kb+HQ853YmXoslur4ieC3JaDXY6DIJuN7MRpY1KukL4GS8FuCbUfnfBdaY2b1+vgeqKN+2qP0qdYPMbK6knnitrQeBz4GZZtavknOKJfUGTsBroV4HHF/WlqQxZcoy2sx+U0WRYs0Hu97Xyur2OLz7NljS41Z+/71T8I2DvbWP9HPg1/LUSpGUDYwCri/NIKlHBed+jbfEDDxn9m05tmJhNHCl/IEC/7y3gTalfWrA5Xihvo7wP/8PUCoE3xRY7TvRAUAHP30T0LiS65YqryJPebUhcLS8vs3GeA6yAFgf1Z/2O+BL35G3N09g8A7/OuU9Qwujyhw9ij4SuNpvHSHpAEmZ/rG38PS3jmWncuxIvNfGsyU1lHQY3tvAJKpX5+OB8/1+xBZ4PwTf++e2BbaY2VDgEaAP0EJSP/94uqRDoo35bypNzWwE8L/AYRXY6hl12rd49dzZz5vp1z/ses9izVeWcutWUgdglZk9D7xQpkzR7FDw9d8MzqggXylln6NAFHyTlb3y18XMZkp6CM85RIAfgBuAZyX9iFcv44Cryjn9euBl/zV8Dd4//4AythbGUIwX8F+FJBXh9a09I+lxoPSVcCl+N4SkaXgOprQV8hrwoaTpeI5ltv/d8iRN8AcOPgE+LnPd54B/+ecVA78FjgKmAavxXgUBLgH+LW9aznz/e6YCQyU1xWsBDcZr6ZTlUeBtSVeUuf4LeK+GU+R9wTXA2f6xUXhdJR+Y2fYy+S8D1vnlfdDMJpRz/y4tpxylDMPrkpmGF3z9djNb6R87FHhEUgle//TV/nWe8r9nGvBPIHpJYWPgA3kqtgJursTWowBmtkbSpcAbvqMCuAevr3cQ8Kmk5WY2oKJ8Ze7tVjznV1Xd9gdu85+xzUC50/L8H+S/4P3ALMN/niqh7HN0qZltq+KcPRa3RNThcDjiZG99tXc4HI7AcI7U4XA44sQ5UofD4YgT50gdDocjTpwjdTgcjjhxjtSxC5Ii2rku+x3FEJWoElvRa9MrjYIkLybAUTW4xkJJu6lNVpReJs/mal4raSNjOcLFOVJHWbaaWQ8z6wZsp8xcWtUw0pBVHQWpP958Vocj6XCO1FEZ44HO2j2CVEWRhiTpGUlzJH0GtCw1pF2jIJ0iL7LRNHkRrDriOez/9VvDx6riaFzN5UWZminpBWJYBirpfXmRnGb6iwSijz3hp4/xVz0haX9Jn/rnjJd0YCC16dhj2StXNjmqxm95nsrO5Zo9gW5mtsB3RhvNrJe/+maCpFF40au64gXdaIW3vPWlMnZb4AVjOc63le0HbPk3XmSr0pB0rwNPmNlXkvbFWwJ5EHAfXpCVv8gLvXd5DF/n9/41MoCJkt41szy84CyTzOx/Jd3r274Ob6XRVWY2T1IfvFU8x9egGh17Cc6ROsqSIWmqvz8eeBHvlTuWSEPHsTPK0nJJn5djvy9edKcFsFvkpmgqisZ1HH70LTP7WNL6GL7TDZJ+6e+398uahxcQ5i0/fSjwnn+No/CW5ZaeXx+HoxKcI3WUZauZ9YhO0O4RsMqNNCTptADLUVk0rpiR1B/PKfczsy3yokxVFCXL/OtuKFsHDkdluD5SR02oKIrTOHZGWWqDF8ylLN/iRbHv5J9bGrmpbGSjiqJxjcMLtIKkU/ECPldGU2C970QPxGsRl5LCzuhUv8XrMsgHFkj6tX8NyYs65XBUiHOkjprwAl7/5xQ/EtF/8N5uhgHz/GOvUE5AYjNbgxfN/T15Ea1KX60/BH5ZOtiEF43rSH8waxY7Zw/8Gc8Rz8R7xV9cRVk/BdIk/YQn1fFt1LECoLf/HY7HUwIALzzc5X75ZgJn4XBUgov+5HA4HHHiWqQOh8MRJ86ROhwOR5w4R+pwOBxx4hypw+FwxIlzpA6HwxEnzpE6HA5HnDhH6nA4HHHy/9cNcHYCBikFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(nnet_p4, X_test_p4, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "749c8d87-9f28-4392-a397-ea5029bf33fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precisión Global': 0.9098156452416543,\n",
       " 'Error Global': 0.09018435475834574,\n",
       " 'Precisión \"cero\"': 0.9554317548746518,\n",
       " 'Precisión \"cinco\"': 0.90625,\n",
       " 'Precisión \"cuatro\"': 0.895,\n",
       " 'Precisión \"dos\"': 0.8838383838383839,\n",
       " 'Precisión \"nueve\"': 0.96045197740113,\n",
       " 'Precisión \"ocho\"': 0.8734939759036144,\n",
       " 'Precisión \"seis\"': 0.9235294117647059,\n",
       " 'Precisión \"siete\"': 0.891156462585034,\n",
       " 'Precisión \"tres\"': 0.8072289156626506,\n",
       " 'Precisión \"uno\"': 0.9356060606060606}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prec_multi(mat_cfn_p4, labels_dig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a286e71-4021-407f-9df3-151445606dfc",
   "metadata": {},
   "source": [
    "En general vemos que las precisiones por dígito bajaron en este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c1bd50-a762-45aa-aa65-89ff81f00439",
   "metadata": {},
   "source": [
    "Ahora hacemos una agrupación por bloques, pero utilizando el máximo en cada bloque, veamos lo que sucede con la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "85e632a7-5308-4831-8984-5a726c1481b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hacer_bloques_max(data,p):\n",
    "    \n",
    "    data_dim = int(math.sqrt(data.shape[1]))\n",
    "    \n",
    "    if data_dim % p == 0:\n",
    "        \n",
    "        q = int(data_dim / p)\n",
    "        data_blocked = {}\n",
    "        for i in range(q):\n",
    "            for j in range(q):\n",
    "                data_blocked[f'V{i}_{j}']=[]\n",
    "        data_blocked = pd.DataFrame({})\n",
    "        \n",
    "        for r in range(data.shape[0]):\n",
    "            ### Hacer un bloque de cada fila ###\n",
    "            fila=data.iloc[r].tolist()\n",
    "            x = np.array(fila)\n",
    "            x = x.reshape(data_dim, data_dim)\n",
    "            data_blocked_fila={}\n",
    "            for i in range(q):\n",
    "                for j in range(q):\n",
    "                    \n",
    "                    bloque=[]\n",
    "                    for k in range(p):\n",
    "                        bloque.append(x[p*i+k][p*j:p*(j+1)])\n",
    "                    bloque=np.array([bloque])\n",
    "                    \n",
    "                    mean_bloque = np.max(bloque)  ### AQUI CAMBIAMOS A USAR EL MAXIMO !!\n",
    "                    data_blocked_fila[f'V_{i}_{j}']=[mean_bloque]\n",
    "                    \n",
    "            data_blocked_fila = pd.DataFrame(data_blocked_fila)\n",
    "            data_blocked = data_blocked.append(data_blocked_fila, ignore_index=True)\n",
    "                \n",
    "        return data_blocked\n",
    "    else:\n",
    "        raise Exception(\"No se pueden hacer bloques de este tamaño\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2389e5ed-fead-46cf-b79f-eda8f336e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p4m = hacer_bloques_max(data = X_train, p = 4)\n",
    "X_test_p4m = hacer_bloques_max(data = X_test, p = 4)\n",
    "y_train_p4m = zipdata_train['Numero']\n",
    "y_test_p4m = zipdata_test['Numero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "018d1f04-f93e-4f8b-8f67-a00c3c903cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[316,   1,   0,  10,   1,   8,  15,   0,   1,   7],\n",
       "       [  5, 120,   2,   4,   3,   3,   4,   0,  17,   2],\n",
       "       [  2,   1, 163,   5,  20,   0,   3,   2,   1,   3],\n",
       "       [  9,   3,   1, 171,   1,   2,   1,   1,   5,   4],\n",
       "       [  0,   0,  20,   1, 136,   4,   0,   9,   1,   6],\n",
       "       [ 11,   8,   4,   4,   6,  95,   4,   1,   8,  25],\n",
       "       [ 15,   1,   0,   4,   0,   0, 147,   0,   3,   0],\n",
       "       [  0,   0,   9,   0,  15,   4,   0, 115,   1,   3],\n",
       "       [  8,  17,   2,   9,   2,   5,   1,   4, 116,   2],\n",
       "       [  0,   1,   6,   2,   0,   3,   5,   5,   0, 242]], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet_p4m = MLPClassifier(\n",
    "    hidden_layer_sizes = (250,100,50,25),\n",
    "    max_iter = 50000,\n",
    "    activation = 'relu',\n",
    "    solver = 'adam', \n",
    "    random_state=0) #Parametros indicados en la tarea\n",
    "\n",
    "nnet_p4m.fit(X_train_p4m.values, y_train_p4m)\n",
    "prediccion_p4m = nnet_p4m.predict(X_test_p4m.values)\n",
    "\n",
    "mat_cfn_p4m = confusion_matrix(y_test, prediccion_p4m)\n",
    "mat_cfn_p4m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "18948e58-7b2d-4560-844d-f2594f5dc449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precisión Global': 0.807673143996014,\n",
       " 'Error Global': 0.19232685600398602,\n",
       " 'Precisión \"cero\"': 0.8802228412256268,\n",
       " 'Precisión \"cinco\"': 0.75,\n",
       " 'Precisión \"cuatro\"': 0.815,\n",
       " 'Precisión \"dos\"': 0.8636363636363636,\n",
       " 'Precisión \"nueve\"': 0.768361581920904,\n",
       " 'Precisión \"ocho\"': 0.572289156626506,\n",
       " 'Precisión \"seis\"': 0.8647058823529412,\n",
       " 'Precisión \"siete\"': 0.782312925170068,\n",
       " 'Precisión \"tres\"': 0.6987951807228916,\n",
       " 'Precisión \"uno\"': 0.9166666666666666}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prec_multi(mat_cfn_p4m, labels_dig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa6f48b-10c2-408c-b53d-a4a2acaab1de",
   "metadata": {},
   "source": [
    "Aquí podemos observar que la agrupación en bloques de $4 \\times 4$ tomando el máximo, en realidad bajó mucho más el desempeño del clasificador. Por eso nos quedamos con el original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8031c4b-081d-49a2-b0c9-ca24b307e168",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='question_container'>\n",
    "    <h2> Pregunta 4 </h2>\n",
    "    <p> Represente en un grafo dirigido la Red Neuronal que tiene la siguiente entrada:</p>\n",
    "    $$\n",
    "    x = \\begin{pmatrix}\n",
    "    -2 \\\\\n",
    "    1 \\\\\n",
    "    1 \\\\\n",
    "    3\n",
    "    \\end{pmatrix}.\n",
    "    $$\n",
    "    <p> Tiene las siguientes matrices de pesos </p>\n",
    "    $$\n",
    "    W_1 = \\begin{pmatrix}\n",
    "    1 & 2 & 0 & 4 \\\\\n",
    "    5 & 3 & 1 & 2 \\\\\n",
    "    2 & 3 & 0 & 2\n",
    "    \\end{pmatrix} \\quad W_2 = \\begin{pmatrix}\n",
    "    4 & 2 & 3 \\\\\n",
    "    1 & 3 & 6\n",
    "    \\end{pmatrix},\n",
    "    $$\n",
    "    tiene el siguiente bias:\n",
    "    $$\n",
    "    b = \\begin{pmatrix}\n",
    "    -6 \\\\\n",
    "    -2\n",
    "    \\end{pmatrix}.\n",
    "    $$\n",
    "    Además use una función de activación tipo <strong> Tangente Hiperbólica </strong>, es decir:\n",
    "    $$\n",
    "    f(x) = \\frac{2}{1+ e^{-2x}} + 1.\n",
    "    $$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42293e8-2421-4295-9992-256e16522e0b",
   "metadata": {},
   "source": [
    "La imagen del grafo dirigido para esta red neuronal se encuentra adjunta en la entrega de la tarea como el archivo `Tarea12_Jimmy_Calvo_grafo_dirigido.png`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e3755-9afc-4637-ac45-22d69774fa7e",
   "metadata": {},
   "source": [
    "Justificación con cálculos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "172cad04-3887-4df6-9a9b-c39b0f257cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]\n",
      " [ 0]\n",
      " [ 5]]\n",
      "[[57]\n",
      " [40]]\n"
     ]
    }
   ],
   "source": [
    "primera_capa = np.matmul(\n",
    "    np.array([ [1,2,0,4], [5,3,1,2], [2,3,0,2] ]),\n",
    "    np.array([ [-2], [1], [1], [3] ])\n",
    ")\n",
    "\n",
    "segunda_capa = np.matmul(\n",
    "    np.array([ [4,2,3], [1,3,6] ]),\n",
    "    primera_capa\n",
    ") + np.array([ [-6], [-2] ])\n",
    "\n",
    "print(primera_capa)\n",
    "print(segunda_capa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fe3309c5-db1d-46b0-863c-1a2b0840e11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/(1+math.exp(-1*57)) + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a18ded07-4aff-47b6-b46c-7db91d7b6bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/(1+math.exp(-1*40)) + 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d223636-2aaa-4af5-828e-703d04e44d4e",
   "metadata": {},
   "source": [
    "<div class='question_container'>\n",
    "    <h2> Pregunta 5 </h2>\n",
    "    <p> [no usar <code>MLPClassifier</code>] Para la Tabla de Datos que se muestra seguidamente donde $x^j$ para $j = 1, 2, 3$ son las variables predictoras y la variable a predecir es $z$. Diseñe y programe a pie una Red Neuronal de una capa (Perceptron):</p>\n",
    "    <table style = \"width:20%;\">\n",
    "        <thead>\n",
    "        <tr>\n",
    "            <th> $x^1$ </th>\n",
    "            <th> $x^2$ </th>\n",
    "            <th> $x^3$ </th>\n",
    "            <th> $z$ </th>\n",
    "         </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "        <tr>\n",
    "            <td> 1 </td>\n",
    "            <td> 0 </td>\n",
    "            <td> 0 </td>\n",
    "            <td> 1 </td>\n",
    "         </tr>\n",
    "            <tr>\n",
    "            <td> 1 </td>\n",
    "            <td> 0 </td>\n",
    "            <td> 1 </td>\n",
    "            <td> 1 </td>\n",
    "         </tr>\n",
    "            <tr>\n",
    "            <td> 1 </td>\n",
    "            <td> 1 </td>\n",
    "            <td> 0 </td>\n",
    "            <td> 0 </td>\n",
    "         </tr>\n",
    "            <tr>\n",
    "            <td> 1 </td>\n",
    "            <td> 1 </td>\n",
    "            <td> 1 </td>\n",
    "            <td> 0 </td>\n",
    "         </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "    <p> Es decir, encuentre todos los posibles pesos $w_1, w_2, w_3$ y umbrales $\\theta$ para la Red Neuronal que se muestra en el siguiente gráfico (ver enunciado de la tarea).</p>\n",
    "    <p> Use una función de activación tipo <strong>Sigmoidea</strong>, es decir:</p>\n",
    "    $$\n",
    "    f(x) = \\frac{1}{1 + e^{-x}}.\n",
    "    $$\n",
    "    <p> Para esto escriba una Clase en <code>Python</code> que incluya los métodos necesarios pra implementar esta Red Neuronal. </p>\n",
    "    <p> Se deben hacer variar los pesos $w_j$ con $j = 1,2,3$ en los siguientes valores $v=(-1,-0.9,-0.8,...,0,...,0.8,0.9,1)$ y haga variar $\\theta$ en $u=(0,0.1,...,0.8,0.9,1)$. Escoja los pesos $w_j$ con $j = 1, 2, 3$ y el umbral $\\theta$ de manera que se minimiza el error cuadrático medio: </p>\n",
    "    $$\n",
    "        E(w_1,w_2,w_3) = \\frac{1}{4}\\sum_{i=1}^4 \\left[ I \\left[ f\\left( \\sum_{j=1}^3 w_j\\cdot x_i^j - \\theta \\right)\\right] - z_i\\right]^2\n",
    "    $$\n",
    "    <p> donde $x_i^j$ es la entrada en la fila $i$ de la variable $x^j$ e $I(t)$ se define como sigue:</p>\n",
    "    $$\n",
    "        I(t) = \\begin{cases}\n",
    "        1 & \\text{ si } t \\geq \\frac{1}{2} \\\\\n",
    "        0 & \\text{ si } t < \\frac{1}{2} \\\\\n",
    "        \\end{cases}\n",
    "    $$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f8180-6894-46a8-aa7e-52a7fbcd109b",
   "metadata": {},
   "source": [
    "**Respuesta** Nuestra matriz tomará una matriz de tamaño $m \\times n$ y un vector de respuestas $z$ para calcular este Perceptrón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48f61adb-4717-4f50-b50c-dc8036f29b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, X, z):\n",
    "        \n",
    "        self.X = X\n",
    "        self.z = y\n",
    "        self.m = X.shape[0]\n",
    "        self.n = X.shape[1]\n",
    "        \n",
    "    def f(self,x):\n",
    "        return 1/(1+math.exp(-1*x))\n",
    "        \n",
    "    def I(self,t):\n",
    "        \n",
    "        if t < 0.5:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def evaluar_MSE(self, w, theta):\n",
    "        \n",
    "        MSE = 0\n",
    "        \n",
    "        for i in range(self.m):\n",
    "            \n",
    "            eval_pt = sum([w[j]*self.X[i,j] for j in range(len(w))]) - theta\n",
    "            eval_val = self.f(eval_pt)\n",
    "            MSE = MSE + (self.I(eval_val) - self.z[i])**2\n",
    "        \n",
    "        return MSE\n",
    "    \n",
    "    def encontrar_arquitectura(self):\n",
    "        \n",
    "        valores = pd.DataFrame({})\n",
    "        \n",
    "        ### Aquí creamos todas las combinaciones posibles para los valores de theta y los pesos w.\n",
    "        v = [round(vt, 1) for vt in np.linspace(-1,1,21)]\n",
    "        u = [round(ut, 1) for ut in np.linspace(0,1,11)]\n",
    "        combs = [v]*self.n\n",
    "        combs.append(u)\n",
    "        all_combs = list(itertools.product(*combs))\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for combo in tqdm(all_combs):\n",
    "            # Para cada combinacion, evaluamos el MSE, todo quedará en un dataframe.\n",
    "            MSE_tupla = self.evaluar_MSE(w = combo[0:self.n], theta = combo[-1])\n",
    "            valores_tupla = pd.DataFrame({\n",
    "                'MSE': [MSE_tupla],\n",
    "                'theta': [combo[-1]]\n",
    "            })\n",
    "            for r in range(self.n):\n",
    "                valores_tupla[f'w_{r+1}'] = [combo[r]]\n",
    "            \n",
    "            valores = valores.append(valores_tupla, ignore_index = True)\n",
    "            \n",
    "        end = time.time()\n",
    "        print(f\"Buscar las arquitecturas que minimizan el MSE duró {end - start} segundos.\")\n",
    "                           \n",
    "        self.resultados_grid = valores\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"\"\"\n",
    "        \n",
    "        X: {self.X}\n",
    "        x: {self.z}\n",
    "        \n",
    "        Mejores valores para los pesos y el bias:\n",
    "        \n",
    "        {self.resultados_grid.sort_values(by=['MSE']).head(5)}\n",
    "        \n",
    "        =========================================\n",
    "        \n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bb326c08-94e0-4076-9876-7041f447d363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 101871/101871 [02:57<00:00, 575.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscar las arquitecturas que minimizan el MSE duró 177.08615446090698 segundos.\n",
      "\n",
      "        \n",
      "        X: [[1 0 0]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 1 1]]\n",
      "        x: [1 1 0 0]\n",
      "        \n",
      "        Mejores valores para los pesos y el bias:\n",
      "        \n",
      "               MSE  theta  w_1  w_2  w_3\n",
      "97367    0    0.6  1.0 -0.9  0.0\n",
      "87847    0    0.1  0.8 -0.8 -0.4\n",
      "87848    0    0.2  0.8 -0.8 -0.4\n",
      "87849    0    0.3  0.8 -0.8 -0.4\n",
      "87850    0    0.4  0.8 -0.8 -0.4\n",
      "        \n",
      "        =========================================\n",
      "        \n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.array([ [ 1, 0, 0] , [1, 0, 1], [1, 1, 0], [1, 1, 1] ])\n",
    "z = np.array([1, 1, 0, 0])\n",
    "\n",
    "mi_perceptron = Perceptron(X, z)\n",
    "mi_perceptron.encontrar_arquitectura()\n",
    "print(mi_perceptron.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "02008480-fc9a-455e-a264-21d7d39b7876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si usamos la primera fila del resultado que vemos arriba.\n",
    "mi_perceptron.evaluar_MSE(w = [1,-0.9, 0], theta=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9057abe8-9058-4fdf-8fe2-b172fb44940a",
   "metadata": {},
   "source": [
    "Verificamos que obtuvimos el ajuste perfecto en este caso, porque obtuvimos un MSE de $0$. Para eso usamos la primera fila, que dió este MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "505eeff8-d849-4b99-a63e-70eb3c4377ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion = []\n",
    "for i in range(X.shape[0]):\n",
    "    val = [X[i,j] for j in range(X.shape[1])]\n",
    "    evval = 1*val[0] -0.9*val[1] + 0*val[2] - 0.6\n",
    "    sigm = 1/(1+math.exp(-1*evval))\n",
    "    if sigm < 0.5:\n",
    "        prediccion.append(0)\n",
    "    else:\n",
    "        prediccion.append(1)\n",
    "prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad22dd4a-fc44-47fa-b305-3de647932960",
   "metadata": {},
   "source": [
    "Es igual al $z$ dado en el ejercicio. Con esto pudimos encontrar una arquitectura que se ajusta a este vector."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
